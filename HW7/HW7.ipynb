{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408bbdaf",
   "metadata": {},
   "source": [
    "# \"Pre-lecture\" HW \n",
    "\n",
    "*link of chat history:*\n",
    "\n",
    "https://chatgpt.com/share/67362f2e-1910-8005-9458-7631ec374637"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22e78eb",
   "metadata": {},
   "source": [
    "## 1. Explain succinctly in your own words (but working with a ChatBot if needed)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db46c3",
   "metadata": {},
   "source": [
    "1. the difference between **Simple Linear Regression** and **Multiple Linear Regression**; and the benefit the latter provides over the former\n",
    "\n",
    "Simple Linear Regression models the relationship between a single independent variable (predictor) and a dependent variable by fitting a linear equation while Multiple Linear Regression extends Simple Linear Regression by incorporating two or more independent variables to predict a dependent variable.\n",
    "\n",
    "Benefit: Multiple Linear Regression can capture more complex relationships by accounting for additional factors, leading to potentially more accurate and nuanced predictions.\n",
    "\n",
    "2. the difference between using a **continuous variable** and an **indicator variable** in **Simple Linear Regression**; and these two **linear forms**\n",
    "\n",
    "Continuous variable represents numerical values that vary across a range, such as age or income. The relationship is modeled continuously, capturing variations in Y based on the range of X. And indicator variable in Simple Linear Regression represents binary (0/1) categories. In Simple Linear Regression it only shifts the intercept based on the category but does not vary continuously. \n",
    "\n",
    "A continuous variable in Simple Linear Regression allows for a slope adjustment across a spectrum of values, while an indicator variable results in a model with separate intercepts for each category, indicating a mean shift rather than a continuous trend.\n",
    "\n",
    "3. the change that happens in the behavior of the model (i.e., the expected nature of the data it models) when a single **indicator variable** is introduced alongside a **continuous variable** to create a **Multiple Linear Regression**; and these two **linear forms** (i.e., the **Simple Linear Regression** versus the **Multiple Linear Regression**)\n",
    "\n",
    "When an indicator variable is added alongside a continuous variable in MLR, the model can represent two different intercepts (one for each category of the indicator variable) but maintains the same slope for the continuous variable across categories.\n",
    "\n",
    "In SLR, we have one intercept and slope. Adding an indicator in MLR leads to two intercepts (one for each category of the indicator variable) but with a single slope for the continuous predictor across both groups. This means the model represents two parallel lines with distinct intercepts for each category.\n",
    "\n",
    "4. the effect of adding an **interaction** between a **continuous** and an **indicator variable** in **Multiple Linear Regression** models; and this **linear form**\n",
    "\n",
    "For MLR this allows the slope of the continuous variable to vary by category. Now, instead of parallel lines, each category can have a distinct slope, capturing different trends within each group. This flexibility enables the model to better fit data with differing relationships between the continuous variable and the outcome across categories.\n",
    "\n",
    "The linear form is \n",
    "\n",
    "$Y = \\beta_0 + \\beta_1X + \\beta_2Z + \\beta_3(X \\times Z) + \\epsilon$\n",
    "\n",
    "\n",
    "5. the behavior of a **Multiple Linear Regression** model (i.e., the expected nature of the data it models) based only on **indicator variables** derived from a **non-binary categorical variable**; this **linear form**; and the necessarily resulting **binary variable encodings** it utilizes\n",
    "\n",
    "When only indicator variables derived from a non-binary categorical variable are used in MLR, the model essentially captures mean differences across these categories without slopes or continuous variations.\n",
    "Linear Form: \n",
    "\n",
    "The model form is $Y = \\beta_0 + \\beta_1I_1 + \\beta_2I_2 + \\epsilon$\n",
    "\n",
    "$I_1$, $I_2$ are binary encodings for the non-binary categories. Only two indicator variables are needed due to multicollinearity (the “dummy variable trap”), which creates an over-specified model.\n",
    "\n",
    "Each non-binary category is encoded into separate indicator (dummy) variables, resulting in a purely categorical model that can only shift intercepts among levels rather than providing a continuous prediction based on a gradient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7680178c",
   "metadata": {},
   "source": [
    "## 2. Explain in your own words (but working with a ChatBot if needed) what the specific (outcome and predictor) variables are for the scenario below; whether or not any meaningful interactions might need to be taken into account when predicting the outcome; and provide the linear forms with and without the potential interactions that might need to be considered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f66a6b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> Imagine a company that sells sports equipment. The company runs advertising campaigns on TV and online platforms. The effectiveness of the TV ad might depend on the amount spent on online advertising and vice versa, leading to an interaction effect between the two advertising mediums. \n",
    "\n",
    "Outcome Variable: \n",
    "\n",
    "The sales revenue generated by the company from its sports equipment.This is what the company aims to predict based on its advertising campaigns.\n",
    "\n",
    "Predictor Variables:\n",
    "\n",
    "TV Advertising Spend (TV): A continuous variable representing the amount spent on TV advertising.\n",
    "\n",
    "Online Advertising Spend (Online): A continuous variable representing the amount spent on online advertising.\n",
    "\n",
    "\n",
    "1. Explain how to use these two formulas to make **predictions** of the **outcome**, and give a high level explaination in general terms of the difference between **predictions** from the models with and without the **interaction** \n",
    "\n",
    "If we think there is without interaction which means TV and Online ad spend independently influence sales without interacting, the linear model is: $Sales = \\beta_0 + \\beta_1TV + \\beta_2Online + \\epsilon$\n",
    "\n",
    "$\\beta_0$ represents the effect of TV ad spend on sales, assuming Online ad spend is constant.\n",
    "\n",
    "$\\beta_2$ represents the effect of Online ad spend on sales, assuming TV ad spend is constant.\n",
    "\n",
    "If we consider that the effect of TV ad spend might depend on Online ad spend and vice versa, we add an interaction term: $Sales = \\beta_0 + \\beta_1TV + \\beta_2Online + \\beta_3(TV \\times Online)+ \\epsilon$\n",
    "\n",
    "$\\beta_3$ represents the interaction effect between TV and Online advertising. It shows how the effect of one type of advertising changes depending on the amount spent on the other type.\n",
    "\n",
    "The difference between predictions from the models with and without the interaction is that, the model without interaction assumes that TV and Online ad spending have independent effects on sales, so the predicted sales is simply the sum of their individual contributions while the model with interaction term modifies the effect of TV spending based on the level of Online spending, and vice versa. \n",
    "\n",
    "This means that at higher levels of one type of spending, the effect of the other may increase or decrease, leading to potentially higher or lower predicted sales than in the independent-effects model.\n",
    "\n",
    "2. Explain how to update and use the implied two formulas to make predictions of the outcome if, rather than considering two continuous predictor variables, we instead suppose the advertisement budgets are simply categorized as either \"high\" or \"low\" (binary variables) \n",
    "\n",
    "To update the continuouse predivtor variables as simply categorized as either \"high\" ot \"low\". \n",
    "\n",
    "We let TV be a binary variable, where 1 represents a \"high\" TV budget and 0 represents a \"low\" TV budget. and Online be a binary variable, where 1 represents a \"high\" Online budget and 0 represents a \"low\" Online budget.\n",
    "\n",
    "So the models should also changed into:\n",
    "\n",
    "Without interaction: \n",
    "\n",
    "$Sales = \\beta_0 + \\beta_1 1_{[\\text{TV is high}=1]}[\\text{TV is high}] + \\beta_2 1_{[\\text{Online is high}=1]}[\\text{Online is high}] + \\epsilon$ \n",
    "\n",
    "With interaction: \n",
    "\n",
    "$Sales = \\beta_0 + \\beta_1 1_{[\\text{TV is high}=1]}[\\text{TV is high}] + \\beta_2 1_{[\\text{Online is high}=1]}[\\text{Online is high}] + \\beta_3 (1_{[\\text{TV is high}=1]}[\\text{TV is high}] \\times 1_{[\\text{Online is high}=1]}[\\text{Online is high}]) + \\epsilon$ \n",
    "\n",
    "$\\beta_0$: The baseline sales when both TV and Online budgets are \"low.\"\n",
    "\n",
    "$\\beta_1$: The additional effect on sales when the TV budget is \"high\" (compared to low), assuming the Online budget stays constant.\n",
    "\n",
    "$\\beta_2$: The additional effect on sales when the Online budget is \"high\" (compared to low), assuming the TV budget stays constant.\n",
    "\n",
    "$\\beta_3$: The interaction effect on sales when both TV and Online budgets are high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c849420",
   "metadata": {},
   "source": [
    "## 4. Explain the apparent contradiction between the factual statements regarding the fit below that \"the model only explains 17.6% of the variability in the data\" while at the same time \"many of the coefficients are larger than 10 while having strong or very strong evidence against the null hypothesis of 'no effect'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce49f4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>719</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>719</td>\n",
       "      <td>DiancieMega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>721</td>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                   Name   Type 1  Type 2  HP  Attack  Defense  \\\n",
       "0      1              Bulbasaur    Grass  Poison  45      49       49   \n",
       "1      2                Ivysaur    Grass  Poison  60      62       63   \n",
       "2      3               Venusaur    Grass  Poison  80      82       83   \n",
       "3      3  VenusaurMega Venusaur    Grass  Poison  80     100      123   \n",
       "4      4             Charmander     Fire     NaN  39      52       43   \n",
       "..   ...                    ...      ...     ...  ..     ...      ...   \n",
       "795  719                Diancie     Rock   Fairy  50     100      150   \n",
       "796  719    DiancieMega Diancie     Rock   Fairy  50     160      110   \n",
       "797  720    HoopaHoopa Confined  Psychic   Ghost  80     110       60   \n",
       "798  720     HoopaHoopa Unbound  Psychic    Dark  80     160       60   \n",
       "799  721              Volcanion     Fire   Water  80     110      120   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0         65       65     45           1      False  \n",
       "1         80       80     60           1      False  \n",
       "2        100      100     80           1      False  \n",
       "3        122      120     80           1      False  \n",
       "4         60       50     65           1      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "795      100      150     50           6       True  \n",
       "796      160      110    110           6       True  \n",
       "797      150      130     70           6       True  \n",
       "798      170      130     80           6       True  \n",
       "799      130       90     70           6       True  \n",
       "\n",
       "[800 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "# fail https://github.com/KeithGalli/pandas/blob/master/pokemon_data.csv\n",
    "pokeaman = pd.read_csv(url) \n",
    "pokeaman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae91659b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>3.50e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:27:31</td>     <th>  Log-Likelihood:    </th> <td> -3649.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   800</td>      <th>  AIC:               </th> <td>   7323.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   788</td>      <th>  BIC:               </th> <td>   7379.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>   26.8971</td> <td>    5.246</td> <td>    5.127</td> <td> 0.000</td> <td>   16.599</td> <td>   37.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>              <td>   20.0449</td> <td>    7.821</td> <td>    2.563</td> <td> 0.011</td> <td>    4.692</td> <td>   35.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>              <td>   21.3662</td> <td>    6.998</td> <td>    3.053</td> <td> 0.002</td> <td>    7.629</td> <td>   35.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>              <td>   31.9575</td> <td>    8.235</td> <td>    3.881</td> <td> 0.000</td> <td>   15.793</td> <td>   48.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>              <td>    9.4926</td> <td>    7.883</td> <td>    1.204</td> <td> 0.229</td> <td>   -5.982</td> <td>   24.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>              <td>   22.2693</td> <td>    8.709</td> <td>    2.557</td> <td> 0.011</td> <td>    5.173</td> <td>   39.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                    <td>    0.5634</td> <td>    0.071</td> <td>    7.906</td> <td> 0.000</td> <td>    0.423</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.2]</th> <td>   -0.2350</td> <td>    0.101</td> <td>   -2.316</td> <td> 0.021</td> <td>   -0.434</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.3]</th> <td>   -0.3067</td> <td>    0.093</td> <td>   -3.300</td> <td> 0.001</td> <td>   -0.489</td> <td>   -0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.4]</th> <td>   -0.3790</td> <td>    0.105</td> <td>   -3.600</td> <td> 0.000</td> <td>   -0.586</td> <td>   -0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.5]</th> <td>   -0.0484</td> <td>    0.108</td> <td>   -0.447</td> <td> 0.655</td> <td>   -0.261</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.6]</th> <td>   -0.3083</td> <td>    0.112</td> <td>   -2.756</td> <td> 0.006</td> <td>   -0.528</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>337.229</td> <th>  Durbin-Watson:     </th> <td>   1.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2871.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.684</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.649</td>  <th>  Cond. No.          </th> <td>1.40e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                  &        HP        & \\textbf{  R-squared:         } &     0.176   \\\\\n",
       "\\textbf{Model:}                          &       OLS        & \\textbf{  Adj. R-squared:    } &     0.164   \\\\\n",
       "\\textbf{Method:}                         &  Least Squares   & \\textbf{  F-statistic:       } &     15.27   \\\\\n",
       "\\textbf{Date:}                           & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  3.50e-27   \\\\\n",
       "\\textbf{Time:}                           &     15:27:31     & \\textbf{  Log-Likelihood:    } &   -3649.4   \\\\\n",
       "\\textbf{No. Observations:}               &         800      & \\textbf{  AIC:               } &     7323.   \\\\\n",
       "\\textbf{Df Residuals:}                   &         788      & \\textbf{  BIC:               } &     7379.   \\\\\n",
       "\\textbf{Df Model:}                       &          11      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                       &      26.8971  &        5.246     &     5.127  &         0.000        &       16.599    &       37.195     \\\\\n",
       "\\textbf{C(Generation)[T.2]}              &      20.0449  &        7.821     &     2.563  &         0.011        &        4.692    &       35.398     \\\\\n",
       "\\textbf{C(Generation)[T.3]}              &      21.3662  &        6.998     &     3.053  &         0.002        &        7.629    &       35.103     \\\\\n",
       "\\textbf{C(Generation)[T.4]}              &      31.9575  &        8.235     &     3.881  &         0.000        &       15.793    &       48.122     \\\\\n",
       "\\textbf{C(Generation)[T.5]}              &       9.4926  &        7.883     &     1.204  &         0.229        &       -5.982    &       24.968     \\\\\n",
       "\\textbf{C(Generation)[T.6]}              &      22.2693  &        8.709     &     2.557  &         0.011        &        5.173    &       39.366     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                    &       0.5634  &        0.071     &     7.906  &         0.000        &        0.423    &        0.703     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.2]} &      -0.2350  &        0.101     &    -2.316  &         0.021        &       -0.434    &       -0.036     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.3]} &      -0.3067  &        0.093     &    -3.300  &         0.001        &       -0.489    &       -0.124     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.4]} &      -0.3790  &        0.105     &    -3.600  &         0.000        &       -0.586    &       -0.172     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.5]} &      -0.0484  &        0.108     &    -0.447  &         0.655        &       -0.261    &        0.164     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.6]} &      -0.3083  &        0.112     &    -2.756  &         0.006        &       -0.528    &       -0.089     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 337.229 & \\textbf{  Durbin-Watson:     } &    1.505  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2871.522  \\\\\n",
       "\\textbf{Skew:}          &   1.684 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  11.649 & \\textbf{  Cond. No.          } & 1.40e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.176\n",
       "Model:                            OLS   Adj. R-squared:                  0.164\n",
       "Method:                 Least Squares   F-statistic:                     15.27\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           3.50e-27\n",
       "Time:                        15:27:31   Log-Likelihood:                -3649.4\n",
       "No. Observations:                 800   AIC:                             7323.\n",
       "Df Residuals:                     788   BIC:                             7379.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                          26.8971      5.246      5.127      0.000      16.599      37.195\n",
       "C(Generation)[T.2]                 20.0449      7.821      2.563      0.011       4.692      35.398\n",
       "C(Generation)[T.3]                 21.3662      6.998      3.053      0.002       7.629      35.103\n",
       "C(Generation)[T.4]                 31.9575      8.235      3.881      0.000      15.793      48.122\n",
       "C(Generation)[T.5]                  9.4926      7.883      1.204      0.229      -5.982      24.968\n",
       "C(Generation)[T.6]                 22.2693      8.709      2.557      0.011       5.173      39.366\n",
       "Q(\"Sp. Def\")                        0.5634      0.071      7.906      0.000       0.423       0.703\n",
       "Q(\"Sp. Def\"):C(Generation)[T.2]    -0.2350      0.101     -2.316      0.021      -0.434      -0.036\n",
       "Q(\"Sp. Def\"):C(Generation)[T.3]    -0.3067      0.093     -3.300      0.001      -0.489      -0.124\n",
       "Q(\"Sp. Def\"):C(Generation)[T.4]    -0.3790      0.105     -3.600      0.000      -0.586      -0.172\n",
       "Q(\"Sp. Def\"):C(Generation)[T.5]    -0.0484      0.108     -0.447      0.655      -0.261       0.164\n",
       "Q(\"Sp. Def\"):C(Generation)[T.6]    -0.3083      0.112     -2.756      0.006      -0.528      -0.089\n",
       "==============================================================================\n",
       "Omnibus:                      337.229   Durbin-Watson:                   1.505\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2871.522\n",
       "Skew:                           1.684   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.649   Cond. No.                     1.40e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model1_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation) + Q(\"Sp. Def\"):C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") * C(Generation)', data=pokeaman)\n",
    "\n",
    "model2_fit = model2_spec.fit()\n",
    "model2_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562280e",
   "metadata": {},
   "source": [
    "The contradiction lies in the difference between statistical significance and variance explained: \n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum_{i=1}^n(y_i-\\hat y)^2}{\\sum_{i=1}^n(y_i-\\bar y)^2}$$\n",
    "\n",
    "A higher $R^2$ value indicates that the model accounts for more variability in y, suggesting a model that captures the underlying patterns in the data more effectively.\n",
    "\n",
    "But $R^2$ alone does not tell us if individual predictor variables are significantly contributing to explaining this variability or if the relationships are meaningful. It is purely a measure of the model's overall fit, summarizing the total variation explained by all predictors without pinpointing specific predictor importance.\n",
    "\n",
    "The p-values for the coefficients tell us whether there is evidence of an effect. Even with a low $R^2$, individual predictors can still significantly impact HP. This is because significance testing measures whether the predictor’s effect is distinguishable from zero, not how much of the total variability it explains. P-values are used in hypothesis testing to determine whether there is evidence that each individual predictor has a significant effect on the outcome variable, holding other predictors constant. For each coefficient in a multiple linear regression, a p-value assesses the evidence against the null hypothesis (that the coefficient is zero, or has no effect).\n",
    "\n",
    "As a result, we can say, $R^2$ measures the “explanatory power” of a model, while p-value focus on the statistical significance of individual predictors.\n",
    "\n",
    "\n",
    "The interaction term `Q(\"Sp. Def\") * C(Generation)` allows the effect of Sp. Def on HP to vary by generation, capturing different relationships across generations. Thus, the significance of coefficients for these terms tells us about the relationship strength and direction in specific contexts, while $R^2$ tells us how much of HP's total variability this model captures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6ff41",
   "metadata": {},
   "source": [
    "# \"Post-lecture\" HW\n",
    "\n",
    "*link of chat history:*\n",
    "\n",
    "https://chatgpt.com/share/67362f00-708c-8005-a058-319a07f52c9f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e030f3",
   "metadata": {},
   "source": [
    "## 5. Discuss the following (five cells of) code and results with a ChatBot and based on the understanding you arrive at in this conversation explain what the following (five cells of) are illustrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0791e3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>338</td>\n",
       "      <td>Solrock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>224</td>\n",
       "      <td>Octillery</td>\n",
       "      <td>Water</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>600</td>\n",
       "      <td>Klang</td>\n",
       "      <td>Steel</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>265</td>\n",
       "      <td>Wurmple</td>\n",
       "      <td>Bug</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>471</td>\n",
       "      <td>Glaceon</td>\n",
       "      <td>Ice</td>\n",
       "      <td>None</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>225</td>\n",
       "      <td>Delibird</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Flying</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>109</td>\n",
       "      <td>Koffing</td>\n",
       "      <td>Poison</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>373</td>\n",
       "      <td>SalamenceMega Salamence</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Flying</td>\n",
       "      <td>95</td>\n",
       "      <td>145</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                     Name   Type 1   Type 2  HP  Attack  Defense  \\\n",
       "370  338                  Solrock     Rock  Psychic  70      95       85   \n",
       "6      6                Charizard     Fire   Flying  78      84       78   \n",
       "242  224                Octillery    Water     None  75     105       75   \n",
       "661  600                    Klang    Steel     None  60      80       95   \n",
       "288  265                  Wurmple      Bug     None  45      45       35   \n",
       "..   ...                      ...      ...      ...  ..     ...      ...   \n",
       "522  471                  Glaceon      Ice     None  65      60      110   \n",
       "243  225                 Delibird      Ice   Flying  45      55       45   \n",
       "797  720      HoopaHoopa Confined  Psychic    Ghost  80     110       60   \n",
       "117  109                  Koffing   Poison     None  40      65       95   \n",
       "409  373  SalamenceMega Salamence   Dragon   Flying  95     145      130   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "370       55       65     70           3      False  \n",
       "6        109       85    100           1      False  \n",
       "242      105       75     45           2      False  \n",
       "661       70       85     50           5      False  \n",
       "288       20       30     20           3      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "522      130       95     65           4      False  \n",
       "243       65       45     75           2      False  \n",
       "797      150      130     70           6       True  \n",
       "117       60       45     35           1      False  \n",
       "409      120       90    120           3      False  \n",
       "\n",
       "[400 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train,pokeaman_test = \\\n",
    "  train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "pokeaman_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe61ada",
   "metadata": {},
   "source": [
    "This cell sets up the dataset for model training and testing. It splits the pokeaman dataset into two subsets: `pokeaman_train` (50% of the data) and `pokeaman_test` (the remaining 50%).\n",
    "\n",
    "Missing values in the `\"Type 2\"` column are filled with \"None\", ensuring no NaN values interfere with the model. Setting a random seed ensures that the split is reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ef002d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:27:02</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     16:27:02     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        16:27:02   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', \n",
    "                      data=pokeaman_train)\n",
    "model3_fit = model_spec3.fit()\n",
    "model3_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9441dc5",
   "metadata": {},
   "source": [
    "A simple linear regression model `model3_fit` is specified with `HP` as a function of `Attack` and `Defense`.\n",
    "\n",
    "This model is fitted to the `pokeaman_train` dataset, allowing us to predict `HP` based on these two features.\n",
    "\n",
    "The summary output provides various statistics, including the in-sample $R^2$ value, which tells us how well this model explains the variance in `HP` for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6355d95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.14771558304519894\n",
      "'Out of sample' R-squared: 0.21208501873920738\n"
     ]
    }
   ],
   "source": [
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model3)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2c7f6",
   "metadata": {},
   "source": [
    "Here, `yhat_model3` represents predictions on the `pokeaman_test` set using the simple linear model `model3_fit`.\n",
    "The in-sample $R^2$ from the `training data` is printed alongside the out-of-sample $R^2$.\n",
    "\n",
    "The out-of-sample $R^2$ is computed as the squared correlation between the actual test values of `HP` (`y`) and their predictions (`yhat_model3`). \n",
    "\n",
    "A significant drop in this value relative to the in-sample $R^2$ would indicate that the model is overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80fdeb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.23e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:27:25</td>     <th>  Log-Likelihood:    </th> <td> -1738.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3603.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   337</td>      <th>  BIC:               </th> <td>   3855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    62</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                  <td></td>                                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                        <td>  521.5715</td> <td>  130.273</td> <td>    4.004</td> <td> 0.000</td> <td>  265.322</td> <td>  777.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                                                <td>   -6.1179</td> <td>    2.846</td> <td>   -2.150</td> <td> 0.032</td> <td>  -11.716</td> <td>   -0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                                           <td>   -8.1938</td> <td>    2.329</td> <td>   -3.518</td> <td> 0.000</td> <td>  -12.775</td> <td>   -3.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                                         <td>-1224.9610</td> <td>  545.105</td> <td>   -2.247</td> <td> 0.025</td> <td>-2297.199</td> <td> -152.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                                          <td>   -6.1989</td> <td>    2.174</td> <td>   -2.851</td> <td> 0.005</td> <td>  -10.475</td> <td>   -1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]</th>                                        <td> -102.4030</td> <td>   96.565</td> <td>   -1.060</td> <td> 0.290</td> <td> -292.350</td> <td>   87.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense</th>                                                   <td>    0.0985</td> <td>    0.033</td> <td>    2.982</td> <td> 0.003</td> <td>    0.034</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]</th>                                 <td>   14.6361</td> <td>    6.267</td> <td>    2.336</td> <td> 0.020</td> <td>    2.310</td> <td>   26.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                                            <td>   -7.2261</td> <td>    2.178</td> <td>   -3.318</td> <td> 0.001</td> <td>  -11.511</td> <td>   -2.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]</th>                                          <td>  704.8798</td> <td>  337.855</td> <td>    2.086</td> <td> 0.038</td> <td>   40.309</td> <td> 1369.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                                                     <td>    0.1264</td> <td>    0.038</td> <td>    3.351</td> <td> 0.001</td> <td>    0.052</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]</th>                                   <td>    5.8648</td> <td>    2.692</td> <td>    2.179</td> <td> 0.030</td> <td>    0.570</td> <td>   11.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed</th>                                                    <td>    0.1026</td> <td>    0.039</td> <td>    2.634</td> <td> 0.009</td> <td>    0.026</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]</th>                                  <td>   -6.9266</td> <td>    3.465</td> <td>   -1.999</td> <td> 0.046</td> <td>  -13.742</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed</th>                                             <td>   -0.0016</td> <td>    0.001</td> <td>   -2.837</td> <td> 0.005</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]</th>                           <td>   -0.0743</td> <td>    0.030</td> <td>   -2.477</td> <td> 0.014</td> <td>   -0.133</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                                                     <td>   -5.3982</td> <td>    1.938</td> <td>   -2.785</td> <td> 0.006</td> <td>   -9.211</td> <td>   -1.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\")</th>                                   <td> -282.2496</td> <td>  126.835</td> <td>   -2.225</td> <td> 0.027</td> <td> -531.738</td> <td>  -32.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                                              <td>    0.1094</td> <td>    0.034</td> <td>    3.233</td> <td> 0.001</td> <td>    0.043</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\")</th>                            <td>   12.6503</td> <td>    5.851</td> <td>    2.162</td> <td> 0.031</td> <td>    1.141</td> <td>   24.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\")</th>                                             <td>    0.0628</td> <td>    0.028</td> <td>    2.247</td> <td> 0.025</td> <td>    0.008</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                           <td>    3.3949</td> <td>    1.783</td> <td>    1.904</td> <td> 0.058</td> <td>   -0.112</td> <td>    6.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\")</th>                                      <td>   -0.0012</td> <td>    0.000</td> <td>   -2.730</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                    <td>   -0.1456</td> <td>    0.065</td> <td>   -2.253</td> <td> 0.025</td> <td>   -0.273</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                                               <td>    0.0624</td> <td>    0.031</td> <td>    2.027</td> <td> 0.043</td> <td>    0.002</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                             <td>   -3.2219</td> <td>    1.983</td> <td>   -1.625</td> <td> 0.105</td> <td>   -7.122</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>                                        <td>   -0.0014</td> <td>    0.001</td> <td>   -2.732</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                      <td>   -0.0695</td> <td>    0.033</td> <td>   -2.100</td> <td> 0.036</td> <td>   -0.135</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\")</th>                                       <td>   -0.0008</td> <td>    0.000</td> <td>   -1.743</td> <td> 0.082</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                     <td>    0.0334</td> <td>    0.021</td> <td>    1.569</td> <td> 0.117</td> <td>   -0.008</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\")</th>                                <td> 1.629e-05</td> <td> 6.92e-06</td> <td>    2.355</td> <td> 0.019</td> <td> 2.68e-06</td> <td> 2.99e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>              <td>    0.0008</td> <td>    0.000</td> <td>    2.433</td> <td> 0.015</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                                                     <td>   -8.3636</td> <td>    2.346</td> <td>   -3.565</td> <td> 0.000</td> <td>  -12.978</td> <td>   -3.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Atk\")</th>                                   <td>  850.5436</td> <td>  385.064</td> <td>    2.209</td> <td> 0.028</td> <td>   93.112</td> <td> 1607.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                                              <td>    0.1388</td> <td>    0.040</td> <td>    3.500</td> <td> 0.001</td> <td>    0.061</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Atk\")</th>                            <td>    2.1809</td> <td>    1.136</td> <td>    1.920</td> <td> 0.056</td> <td>   -0.054</td> <td>    4.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Atk\")</th>                                             <td>    0.0831</td> <td>    0.038</td> <td>    2.162</td> <td> 0.031</td> <td>    0.007</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                           <td>   -7.3121</td> <td>    3.376</td> <td>   -2.166</td> <td> 0.031</td> <td>  -13.953</td> <td>   -0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Atk\")</th>                                      <td>   -0.0014</td> <td>    0.001</td> <td>   -2.480</td> <td> 0.014</td> <td>   -0.003</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                    <td>   -0.0434</td> <td>    0.022</td> <td>   -2.010</td> <td> 0.045</td> <td>   -0.086</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                                               <td>    0.1011</td> <td>    0.035</td> <td>    2.872</td> <td> 0.004</td> <td>    0.032</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                             <td>  -12.6343</td> <td>    5.613</td> <td>   -2.251</td> <td> 0.025</td> <td>  -23.674</td> <td>   -1.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>                                        <td>   -0.0018</td> <td>    0.001</td> <td>   -3.102</td> <td> 0.002</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                      <td>    0.0151</td> <td>    0.009</td> <td>    1.609</td> <td> 0.109</td> <td>   -0.003</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Atk\")</th>                                       <td>   -0.0012</td> <td>    0.001</td> <td>   -1.860</td> <td> 0.064</td> <td>   -0.002</td> <td> 6.62e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                     <td>    0.1210</td> <td>    0.054</td> <td>    2.260</td> <td> 0.024</td> <td>    0.016</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Atk\")</th>                                <td> 2.125e-05</td> <td>  9.1e-06</td> <td>    2.334</td> <td> 0.020</td> <td> 3.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>              <td> 6.438e-06</td> <td> 7.69e-05</td> <td>    0.084</td> <td> 0.933</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                        <td>    0.1265</td> <td>    0.033</td> <td>    3.821</td> <td> 0.000</td> <td>    0.061</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                      <td>   -5.0544</td> <td>    2.506</td> <td>   -2.017</td> <td> 0.044</td> <td>   -9.983</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                 <td>   -0.0021</td> <td>    0.001</td> <td>   -3.606</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>               <td>   -0.0346</td> <td>    0.017</td> <td>   -1.992</td> <td> 0.047</td> <td>   -0.069</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                <td>   -0.0012</td> <td>    0.000</td> <td>   -2.406</td> <td> 0.017</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0446</td> <td>    0.025</td> <td>    1.794</td> <td> 0.074</td> <td>   -0.004</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                         <td> 1.973e-05</td> <td> 7.28e-06</td> <td>    2.710</td> <td> 0.007</td> <td> 5.41e-06</td> <td>  3.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>    0.0005</td> <td>    0.000</td> <td>    1.957</td> <td> 0.051</td> <td>-2.56e-06</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                  <td>   -0.0013</td> <td>    0.000</td> <td>   -2.740</td> <td> 0.006</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                <td>    0.0841</td> <td>    0.040</td> <td>    2.125</td> <td> 0.034</td> <td>    0.006</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                           <td> 2.379e-05</td> <td> 7.85e-06</td> <td>    3.030</td> <td> 0.003</td> <td> 8.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>         <td> 2.864e-05</td> <td> 7.73e-05</td> <td>    0.370</td> <td> 0.711</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                          <td> 1.284e-05</td> <td> 7.46e-06</td> <td>    1.721</td> <td> 0.086</td> <td>-1.83e-06</td> <td> 2.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0008</td> <td>    0.000</td> <td>   -2.085</td> <td> 0.038</td> <td>   -0.002</td> <td>-4.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                   <td> -2.53e-07</td> <td>  1.1e-07</td> <td>   -2.292</td> <td> 0.023</td> <td> -4.7e-07</td> <td>-3.59e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>-1.425e-06</td> <td> 1.14e-06</td> <td>   -1.249</td> <td> 0.212</td> <td>-3.67e-06</td> <td> 8.19e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.2e+16. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                   &        HP        & \\textbf{  R-squared:         } &     0.467   \\\\\n",
       "\\textbf{Model:}                                                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.369   \\\\\n",
       "\\textbf{Method:}                                                          &  Least Squares   & \\textbf{  F-statistic:       } &     4.764   \\\\\n",
       "\\textbf{Date:}                                                            & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.23e-21   \\\\\n",
       "\\textbf{Time:}                                                            &     16:27:25     & \\textbf{  Log-Likelihood:    } &   -1738.6   \\\\\n",
       "\\textbf{No. Observations:}                                                &         400      & \\textbf{  AIC:               } &     3603.   \\\\\n",
       "\\textbf{Df Residuals:}                                                    &         337      & \\textbf{  BIC:               } &     3855.   \\\\\n",
       "\\textbf{Df Model:}                                                        &          62      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                        &     521.5715  &      130.273     &     4.004  &         0.000        &      265.322    &      777.821     \\\\\n",
       "\\textbf{Legendary[T.True]}                                                &      -6.1179  &        2.846     &    -2.150  &         0.032        &      -11.716    &       -0.520     \\\\\n",
       "\\textbf{Attack}                                                           &      -8.1938  &        2.329     &    -3.518  &         0.000        &      -12.775    &       -3.612     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                                         &   -1224.9610  &      545.105     &    -2.247  &         0.025        &    -2297.199    &     -152.723     \\\\\n",
       "\\textbf{Defense}                                                          &      -6.1989  &        2.174     &    -2.851  &         0.005        &      -10.475    &       -1.923     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]}                                        &    -102.4030  &       96.565     &    -1.060  &         0.290        &     -292.350    &       87.544     \\\\\n",
       "\\textbf{Attack:Defense}                                                   &       0.0985  &        0.033     &     2.982  &         0.003        &        0.034    &        0.164     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]}                                 &      14.6361  &        6.267     &     2.336  &         0.020        &        2.310    &       26.963     \\\\\n",
       "\\textbf{Speed}                                                            &      -7.2261  &        2.178     &    -3.318  &         0.001        &      -11.511    &       -2.942     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]}                                          &     704.8798  &      337.855     &     2.086  &         0.038        &       40.309    &     1369.450     \\\\\n",
       "\\textbf{Attack:Speed}                                                     &       0.1264  &        0.038     &     3.351  &         0.001        &        0.052    &        0.201     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]}                                   &       5.8648  &        2.692     &     2.179  &         0.030        &        0.570    &       11.160     \\\\\n",
       "\\textbf{Defense:Speed}                                                    &       0.1026  &        0.039     &     2.634  &         0.009        &        0.026    &        0.179     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]}                                  &      -6.9266  &        3.465     &    -1.999  &         0.046        &      -13.742    &       -0.111     \\\\\n",
       "\\textbf{Attack:Defense:Speed}                                             &      -0.0016  &        0.001     &    -2.837  &         0.005        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]}                           &      -0.0743  &        0.030     &    -2.477  &         0.014        &       -0.133    &       -0.015     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                                                     &      -5.3982  &        1.938     &    -2.785  &         0.006        &       -9.211    &       -1.586     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\")}                                   &    -282.2496  &      126.835     &    -2.225  &         0.027        &     -531.738    &      -32.761     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                                              &       0.1094  &        0.034     &     3.233  &         0.001        &        0.043    &        0.176     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\")}                            &      12.6503  &        5.851     &     2.162  &         0.031        &        1.141    &       24.160     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\")}                                             &       0.0628  &        0.028     &     2.247  &         0.025        &        0.008    &        0.118     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\")}                           &       3.3949  &        1.783     &     1.904  &         0.058        &       -0.112    &        6.902     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\")}                                      &      -0.0012  &        0.000     &    -2.730  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")}                    &      -0.1456  &        0.065     &    -2.253  &         0.025        &       -0.273    &       -0.018     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                                               &       0.0624  &        0.031     &     2.027  &         0.043        &        0.002    &        0.123     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\")}                             &      -3.2219  &        1.983     &    -1.625  &         0.105        &       -7.122    &        0.678     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}                                        &      -0.0014  &        0.001     &    -2.732  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                      &      -0.0695  &        0.033     &    -2.100  &         0.036        &       -0.135    &       -0.004     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\")}                                       &      -0.0008  &        0.000     &    -1.743  &         0.082        &       -0.002    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                     &       0.0334  &        0.021     &     1.569  &         0.117        &       -0.008    &        0.075     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\")}                                &    1.629e-05  &     6.92e-06     &     2.355  &         0.019        &     2.68e-06    &     2.99e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}              &       0.0008  &        0.000     &     2.433  &         0.015        &        0.000    &        0.001     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                                                     &      -8.3636  &        2.346     &    -3.565  &         0.000        &      -12.978    &       -3.749     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Atk\")}                                   &     850.5436  &      385.064     &     2.209  &         0.028        &       93.112    &     1607.975     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                                              &       0.1388  &        0.040     &     3.500  &         0.001        &        0.061    &        0.217     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Atk\")}                            &       2.1809  &        1.136     &     1.920  &         0.056        &       -0.054    &        4.416     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Atk\")}                                             &       0.0831  &        0.038     &     2.162  &         0.031        &        0.007    &        0.159     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                           &      -7.3121  &        3.376     &    -2.166  &         0.031        &      -13.953    &       -0.671     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Atk\")}                                      &      -0.0014  &        0.001     &    -2.480  &         0.014        &       -0.003    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                    &      -0.0434  &        0.022     &    -2.010  &         0.045        &       -0.086    &       -0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                                               &       0.1011  &        0.035     &     2.872  &         0.004        &        0.032    &        0.170     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                             &     -12.6343  &        5.613     &    -2.251  &         0.025        &      -23.674    &       -1.594     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}                                        &      -0.0018  &        0.001     &    -3.102  &         0.002        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                      &       0.0151  &        0.009     &     1.609  &         0.109        &       -0.003    &        0.034     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Atk\")}                                       &      -0.0012  &        0.001     &    -1.860  &         0.064        &       -0.002    &     6.62e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                     &       0.1210  &        0.054     &     2.260  &         0.024        &        0.016    &        0.226     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Atk\")}                                &    2.125e-05  &      9.1e-06     &     2.334  &         0.020        &     3.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}              &    6.438e-06  &     7.69e-05     &     0.084  &         0.933        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                        &       0.1265  &        0.033     &     3.821  &         0.000        &        0.061    &        0.192     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                      &      -5.0544  &        2.506     &    -2.017  &         0.044        &       -9.983    &       -0.126     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                 &      -0.0021  &        0.001     &    -3.606  &         0.000        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}               &      -0.0346  &        0.017     &    -1.992  &         0.047        &       -0.069    &       -0.000     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                &      -0.0012  &        0.000     &    -2.406  &         0.017        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0446  &        0.025     &     1.794  &         0.074        &       -0.004    &        0.093     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                         &    1.973e-05  &     7.28e-06     &     2.710  &         0.007        &     5.41e-06    &      3.4e-05     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &       0.0005  &        0.000     &     1.957  &         0.051        &    -2.56e-06    &        0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                  &      -0.0013  &        0.000     &    -2.740  &         0.006        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                &       0.0841  &        0.040     &     2.125  &         0.034        &        0.006    &        0.162     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                           &    2.379e-05  &     7.85e-06     &     3.030  &         0.003        &     8.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}         &    2.864e-05  &     7.73e-05     &     0.370  &         0.711        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                          &    1.284e-05  &     7.46e-06     &     1.721  &         0.086        &    -1.83e-06    &     2.75e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0008  &        0.000     &    -2.085  &         0.038        &       -0.002    &    -4.68e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                   &    -2.53e-07  &      1.1e-07     &    -2.292  &         0.023        &     -4.7e-07    &    -3.59e-08     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &   -1.425e-06  &     1.14e-06     &    -1.249  &         0.212        &    -3.67e-06    &     8.19e-07     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.2e+16. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.467\n",
       "Model:                            OLS   Adj. R-squared:                  0.369\n",
       "Method:                 Least Squares   F-statistic:                     4.764\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           4.23e-21\n",
       "Time:                        16:27:25   Log-Likelihood:                -1738.6\n",
       "No. Observations:                 400   AIC:                             3603.\n",
       "Df Residuals:                     337   BIC:                             3855.\n",
       "Df Model:                          62                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================================\n",
       "                                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                          521.5715    130.273      4.004      0.000     265.322     777.821\n",
       "Legendary[T.True]                                                   -6.1179      2.846     -2.150      0.032     -11.716      -0.520\n",
       "Attack                                                              -8.1938      2.329     -3.518      0.000     -12.775      -3.612\n",
       "Attack:Legendary[T.True]                                         -1224.9610    545.105     -2.247      0.025   -2297.199    -152.723\n",
       "Defense                                                             -6.1989      2.174     -2.851      0.005     -10.475      -1.923\n",
       "Defense:Legendary[T.True]                                         -102.4030     96.565     -1.060      0.290    -292.350      87.544\n",
       "Attack:Defense                                                       0.0985      0.033      2.982      0.003       0.034       0.164\n",
       "Attack:Defense:Legendary[T.True]                                    14.6361      6.267      2.336      0.020       2.310      26.963\n",
       "Speed                                                               -7.2261      2.178     -3.318      0.001     -11.511      -2.942\n",
       "Speed:Legendary[T.True]                                            704.8798    337.855      2.086      0.038      40.309    1369.450\n",
       "Attack:Speed                                                         0.1264      0.038      3.351      0.001       0.052       0.201\n",
       "Attack:Speed:Legendary[T.True]                                       5.8648      2.692      2.179      0.030       0.570      11.160\n",
       "Defense:Speed                                                        0.1026      0.039      2.634      0.009       0.026       0.179\n",
       "Defense:Speed:Legendary[T.True]                                     -6.9266      3.465     -1.999      0.046     -13.742      -0.111\n",
       "Attack:Defense:Speed                                                -0.0016      0.001     -2.837      0.005      -0.003      -0.001\n",
       "Attack:Defense:Speed:Legendary[T.True]                              -0.0743      0.030     -2.477      0.014      -0.133      -0.015\n",
       "Q(\"Sp. Def\")                                                        -5.3982      1.938     -2.785      0.006      -9.211      -1.586\n",
       "Legendary[T.True]:Q(\"Sp. Def\")                                    -282.2496    126.835     -2.225      0.027    -531.738     -32.761\n",
       "Attack:Q(\"Sp. Def\")                                                  0.1094      0.034      3.233      0.001       0.043       0.176\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\")                               12.6503      5.851      2.162      0.031       1.141      24.160\n",
       "Defense:Q(\"Sp. Def\")                                                 0.0628      0.028      2.247      0.025       0.008       0.118\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\")                               3.3949      1.783      1.904      0.058      -0.112       6.902\n",
       "Attack:Defense:Q(\"Sp. Def\")                                         -0.0012      0.000     -2.730      0.007      -0.002      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")                       -0.1456      0.065     -2.253      0.025      -0.273      -0.018\n",
       "Speed:Q(\"Sp. Def\")                                                   0.0624      0.031      2.027      0.043       0.002       0.123\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\")                                -3.2219      1.983     -1.625      0.105      -7.122       0.678\n",
       "Attack:Speed:Q(\"Sp. Def\")                                           -0.0014      0.001     -2.732      0.007      -0.002      -0.000\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         -0.0695      0.033     -2.100      0.036      -0.135      -0.004\n",
       "Defense:Speed:Q(\"Sp. Def\")                                          -0.0008      0.000     -1.743      0.082      -0.002       0.000\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         0.0334      0.021      1.569      0.117      -0.008       0.075\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\")                                 1.629e-05   6.92e-06      2.355      0.019    2.68e-06    2.99e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                  0.0008      0.000      2.433      0.015       0.000       0.001\n",
       "Q(\"Sp. Atk\")                                                        -8.3636      2.346     -3.565      0.000     -12.978      -3.749\n",
       "Legendary[T.True]:Q(\"Sp. Atk\")                                     850.5436    385.064      2.209      0.028      93.112    1607.975\n",
       "Attack:Q(\"Sp. Atk\")                                                  0.1388      0.040      3.500      0.001       0.061       0.217\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Atk\")                                2.1809      1.136      1.920      0.056      -0.054       4.416\n",
       "Defense:Q(\"Sp. Atk\")                                                 0.0831      0.038      2.162      0.031       0.007       0.159\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Atk\")                              -7.3121      3.376     -2.166      0.031     -13.953      -0.671\n",
       "Attack:Defense:Q(\"Sp. Atk\")                                         -0.0014      0.001     -2.480      0.014      -0.003      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")                       -0.0434      0.022     -2.010      0.045      -0.086      -0.001\n",
       "Speed:Q(\"Sp. Atk\")                                                   0.1011      0.035      2.872      0.004       0.032       0.170\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Atk\")                               -12.6343      5.613     -2.251      0.025     -23.674      -1.594\n",
       "Attack:Speed:Q(\"Sp. Atk\")                                           -0.0018      0.001     -3.102      0.002      -0.003      -0.001\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                          0.0151      0.009      1.609      0.109      -0.003       0.034\n",
       "Defense:Speed:Q(\"Sp. Atk\")                                          -0.0012      0.001     -1.860      0.064      -0.002    6.62e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                         0.1210      0.054      2.260      0.024       0.016       0.226\n",
       "Attack:Defense:Speed:Q(\"Sp. Atk\")                                 2.125e-05    9.1e-06      2.334      0.020    3.34e-06    3.92e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")               6.438e-06   7.69e-05      0.084      0.933      -0.000       0.000\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                            0.1265      0.033      3.821      0.000       0.061       0.192\n",
       "Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                         -5.0544      2.506     -2.017      0.044      -9.983      -0.126\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                    -0.0021      0.001     -3.606      0.000      -0.003      -0.001\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  -0.0346      0.017     -1.992      0.047      -0.069      -0.000\n",
       "Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                   -0.0012      0.000     -2.406      0.017      -0.002      -0.000\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0446      0.025      1.794      0.074      -0.004       0.093\n",
       "Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                          1.973e-05   7.28e-06      2.710      0.007    5.41e-06     3.4e-05\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           0.0005      0.000      1.957      0.051   -2.56e-06       0.001\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                     -0.0013      0.000     -2.740      0.006      -0.002      -0.000\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    0.0841      0.040      2.125      0.034       0.006       0.162\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                            2.379e-05   7.85e-06      3.030      0.003    8.34e-06    3.92e-05\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          2.864e-05   7.73e-05      0.370      0.711      -0.000       0.000\n",
       "Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                           1.284e-05   7.46e-06      1.721      0.086   -1.83e-06    2.75e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0008      0.000     -2.085      0.038      -0.002   -4.68e-05\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    -2.53e-07    1.1e-07     -2.292      0.023    -4.7e-07   -3.59e-08\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\") -1.425e-06   1.14e-06     -1.249      0.212   -3.67e-06    8.19e-07\n",
       "==============================================================================\n",
       "Omnibus:                      214.307   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2354.664\n",
       "Skew:                           2.026   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.174   Cond. No.                     1.20e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.2e+16. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# That's 6*18*19 = 6*18*19 possible interaction combinations...\n",
    "# ...a huge number that will blow up your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f01bd08",
   "metadata": {},
   "source": [
    "This cell specifies a more complex model (`model4_fit`), using multiple predictors (`Attack`, `Defense`, `Speed`, `Legendary`, `Sp. Def`, `Sp. Atk`) and their interactions.\n",
    "\n",
    "This model incorporates potentially high-dimensional interactions to better capture relationships between `HP` and multiple predictors.\n",
    "\n",
    "Due to computational limits, only a subset of potential interaction terms is included, leaving out categorical terms like `Generation` and `Type`.\n",
    "\n",
    "The model summary gives an in-sample $R^2$ value, which we expect to be higher than the simple model due to its complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5648b6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.46709442115833855\n",
      "'Out of sample' R-squared: 0.002485342598992873\n"
     ]
    }
   ],
   "source": [
    "yhat_model4 = model4_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model4)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2907ae",
   "metadata": {},
   "source": [
    "Predictions for the test set are made using the complex model (`model4_fit`), and both in-sample and out-of-sample  $R^2$ values are printed.\n",
    "\n",
    "If the out-of-sample  $R^2$ or this model drops significantly compared to the in-sample  $R^2$, it would suggest that this model overfits more than the simple model, failing to generalize as well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a5f442",
   "metadata": {},
   "source": [
    "## 6. Work with a ChatBot to understand how the model4_linear_form (linear form specification of model4) creates new predictor variables as the columns of the so-called \"design matrix\" model4_spec.exog (model4_spec.exog.shape) used to predict the outcome variable model4_spec.endog and why the so-called multicollinearity in this \"design matrix\" (observed in np.corrcoef(model4_spec.exog)) contribues to the lack of \"out of sample\" generalization of predictions from model4_fit; then, explain this consisely in your own works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "570d19b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:39:50</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     16:39:50     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        16:39:50   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 343.0 WITHOUT to centering and scaling\n",
    "model3_fit.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e63b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:40:10</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>   69.3025</td> <td>    1.186</td> <td>   58.439</td> <td> 0.000</td> <td>   66.971</td> <td>   71.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Attack))</th>  <td>    8.1099</td> <td>    1.340</td> <td>    6.051</td> <td> 0.000</td> <td>    5.475</td> <td>   10.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Defense))</th> <td>    2.9496</td> <td>    1.340</td> <td>    2.201</td> <td> 0.028</td> <td>    0.315</td> <td>    5.585</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    1.66</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}         &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}                &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}                  & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}                  &     16:40:10     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:}      &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}          &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}              &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}              &      69.3025  &        1.186     &    58.439  &         0.000        &       66.971    &       71.634     \\\\\n",
       "\\textbf{scale(center(Attack))}  &       8.1099  &        1.340     &     6.051  &         0.000        &        5.475    &       10.745     \\\\\n",
       "\\textbf{scale(center(Defense))} &       2.9496  &        1.340     &     2.201  &         0.028        &        0.315    &        5.585     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     1.66  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        16:40:10   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Intercept                 69.3025      1.186     58.439      0.000      66.971      71.634\n",
       "scale(center(Attack))      8.1099      1.340      6.051      0.000       5.475      10.745\n",
       "scale(center(Defense))     2.9496      1.340      2.201      0.028       0.315       5.585\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         1.66\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from patsy import center, scale\n",
    "\n",
    "model3_linear_form_center_scale = \\\n",
    "  'HP ~ scale(center(Attack)) + scale(center(Defense))' \n",
    "model_spec3_center_scale = smf.ols(formula=model3_linear_form_center_scale,\n",
    "                                   data=pokeaman_train)\n",
    "model3_center_scale_fit = model_spec3_center_scale.fit()\n",
    "model3_center_scale_fit.summary()\n",
    "# \"Cond. No.\" is NOW 1.66 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3333493e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.54e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.663  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.54e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Defense))'\n",
    "model4_linear_form_CS += ' * scale(center(Speed)) * Legendary' \n",
    "model4_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# Legendary is an indicator, so we don't center and scale that\n",
    "\n",
    "model4_CS_spec = smf.ols(formula=model4_linear_form_CS, data=pokeaman_train)\n",
    "model4_CS_fit = model4_CS_spec.fit()\n",
    "model4_CS_fit.summary().tables[-1]  # Cond. No. is 2,250,000,000,000,000\n",
    "\n",
    "# The condition number is still bad even after centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75978981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just as the condition number was very bad to start with\n",
    "model4_fit.summary().tables[-1]  # Cond. No. is 12,000,000,000,000,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69016268",
   "metadata": {},
   "source": [
    "`Attack * Defense * Speed` alone creates seven terms.\n",
    "\n",
    "When we add more variables like `Legendary`, `Sp. Def`, and `Sp. Atk` with additional `*`, the number of combinations explodes.\n",
    "\n",
    "Each combination, from individual terms to six-way interactions, becomes a column in the design matrix, creating a highly complex model that suffers from multicollinearity and overfitting.\n",
    "\n",
    "`model4_spec.exog` is the design matrix of all predictor variables and interactions specified in `model4_linear_form`\n",
    "\n",
    "As a result, the `model4_linear_form` creates numerous predictor variables by including main effects and interactions, resulting in a complex design matrix (`model4_spec.exog`) with many correlated columns. This complexity leads to multicollinearity, causing the model to overfit and reducing its ability to make reliable out-of-sample predictions.\n",
    "\n",
    "**Multicollinearity** occurs when two or more columns (predictors) in the design matrix are highly correlated. In `model4_spec.exog`, multicollinearity arises because of the many interaction terms and main effects that overlap in the information they contain. With high multicollinearity, the model struggles to distinguish the unique effect of each predictor because they contain overlapping information. This results in unstable coefficients, where small changes in the data can lead to large swings in the estimated coefficients. Overfitting means that the model fits the noise and specific patterns of the training data instead of learning a general pattern that applies more broadly. And because of multicollinearity, the model learns specific, data-dependent relationships that do not hold for new data. So it lack of \"out of sample\" generalization.\n",
    "\n",
    "\n",
    "\"Out-of-sample generalization\" refers to a model’s ability to make accurate predictions on new, unseen data that was not part of the dataset used to train the model. In other words, it is a measure of how well the model can generalize beyond the specific examples it learned during training. It is the model’s ability to make accurate predictions on new, unseen data. It is essential for ensuring that the model's predictions are reliable in real-world situations and not just specific to the data it was trained on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4ebc11",
   "metadata": {},
   "source": [
    "## 7. Discuss with a ChatBot the rationale and principles by which model5_linear_form is extended and developed from model3_fit and model4_fit; model6_linear_form is extended and developed from model5_linear_form; and model7_linear_form is extended and developed from model6_linear_form; then, explain this breifly and consisely in your own words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a668814",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>9.48e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:16:28</td>     <th>  Log-Likelihood:    </th> <td> -1765.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3624.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   353</td>      <th>  BIC:               </th> <td>   3812.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    46</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>   10.1046</td> <td>   14.957</td> <td>    0.676</td> <td> 0.500</td> <td>  -19.312</td> <td>   39.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>          <td>   -3.2717</td> <td>    4.943</td> <td>   -0.662</td> <td> 0.508</td> <td>  -12.992</td> <td>    6.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>         <td>    9.2938</td> <td>    4.015</td> <td>    2.315</td> <td> 0.021</td> <td>    1.398</td> <td>   17.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>         <td>    2.3150</td> <td>    3.915</td> <td>    0.591</td> <td> 0.555</td> <td>   -5.385</td> <td>   10.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>         <td>    4.8353</td> <td>    4.149</td> <td>    1.165</td> <td> 0.245</td> <td>   -3.325</td> <td>   12.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>         <td>   11.4838</td> <td>    3.960</td> <td>    2.900</td> <td> 0.004</td> <td>    3.696</td> <td>   19.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>         <td>    4.9206</td> <td>    4.746</td> <td>    1.037</td> <td> 0.300</td> <td>   -4.413</td> <td>   14.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dark]</th>     <td>   -1.4155</td> <td>    6.936</td> <td>   -0.204</td> <td> 0.838</td> <td>  -15.057</td> <td>   12.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dragon]</th>   <td>    0.8509</td> <td>    6.900</td> <td>    0.123</td> <td> 0.902</td> <td>  -12.720</td> <td>   14.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Electric]</th> <td>   -6.3641</td> <td>    6.537</td> <td>   -0.974</td> <td> 0.331</td> <td>  -19.220</td> <td>    6.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fairy]</th>    <td>   -1.9486</td> <td>   10.124</td> <td>   -0.192</td> <td> 0.847</td> <td>  -21.859</td> <td>   17.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fighting]</th> <td>    7.0308</td> <td>    7.432</td> <td>    0.946</td> <td> 0.345</td> <td>   -7.586</td> <td>   21.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fire]</th>     <td>    3.0779</td> <td>    6.677</td> <td>    0.461</td> <td> 0.645</td> <td>  -10.055</td> <td>   16.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Flying]</th>   <td>   -2.1231</td> <td>   22.322</td> <td>   -0.095</td> <td> 0.924</td> <td>  -46.025</td> <td>   41.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ghost]</th>    <td>    5.7343</td> <td>    8.488</td> <td>    0.676</td> <td> 0.500</td> <td>  -10.960</td> <td>   22.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Grass]</th>    <td>    3.3275</td> <td>    5.496</td> <td>    0.605</td> <td> 0.545</td> <td>   -7.481</td> <td>   14.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ground]</th>   <td>    9.5118</td> <td>    7.076</td> <td>    1.344</td> <td> 0.180</td> <td>   -4.404</td> <td>   23.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ice]</th>      <td>   -0.9313</td> <td>    7.717</td> <td>   -0.121</td> <td> 0.904</td> <td>  -16.108</td> <td>   14.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Normal]</th>   <td>   18.4816</td> <td>    5.312</td> <td>    3.479</td> <td> 0.001</td> <td>    8.034</td> <td>   28.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Poison]</th>   <td>    8.3411</td> <td>    7.735</td> <td>    1.078</td> <td> 0.282</td> <td>   -6.871</td> <td>   23.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Psychic]</th>  <td>    1.8061</td> <td>    6.164</td> <td>    0.293</td> <td> 0.770</td> <td>  -10.317</td> <td>   13.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Rock]</th>     <td>   -3.8558</td> <td>    6.503</td> <td>   -0.593</td> <td> 0.554</td> <td>  -16.645</td> <td>    8.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Steel]</th>    <td>   -4.0053</td> <td>    8.044</td> <td>   -0.498</td> <td> 0.619</td> <td>  -19.826</td> <td>   11.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Water]</th>    <td>    9.7988</td> <td>    5.166</td> <td>    1.897</td> <td> 0.059</td> <td>   -0.361</td> <td>   19.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dark]</th>     <td>    5.8719</td> <td>   15.185</td> <td>    0.387</td> <td> 0.699</td> <td>  -23.993</td> <td>   35.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dragon]</th>   <td>   13.2777</td> <td>   14.895</td> <td>    0.891</td> <td> 0.373</td> <td>  -16.016</td> <td>   42.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Electric]</th> <td>   14.3228</td> <td>   17.314</td> <td>    0.827</td> <td> 0.409</td> <td>  -19.728</td> <td>   48.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fairy]</th>    <td>    2.8426</td> <td>   14.268</td> <td>    0.199</td> <td> 0.842</td> <td>  -25.218</td> <td>   30.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fighting]</th> <td>    1.9741</td> <td>   14.089</td> <td>    0.140</td> <td> 0.889</td> <td>  -25.735</td> <td>   29.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fire]</th>     <td>    0.2001</td> <td>   15.730</td> <td>    0.013</td> <td> 0.990</td> <td>  -30.736</td> <td>   31.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Flying]</th>   <td>    6.7292</td> <td>   13.581</td> <td>    0.495</td> <td> 0.621</td> <td>  -19.980</td> <td>   33.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ghost]</th>    <td>  -10.9402</td> <td>   15.895</td> <td>   -0.688</td> <td> 0.492</td> <td>  -42.201</td> <td>   20.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Grass]</th>    <td>    2.5119</td> <td>   14.540</td> <td>    0.173</td> <td> 0.863</td> <td>  -26.084</td> <td>   31.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ground]</th>   <td>   13.6042</td> <td>   13.655</td> <td>    0.996</td> <td> 0.320</td> <td>  -13.250</td> <td>   40.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ice]</th>      <td>   19.7950</td> <td>   15.068</td> <td>    1.314</td> <td> 0.190</td> <td>   -9.840</td> <td>   49.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.None]</th>     <td>    7.6068</td> <td>   13.162</td> <td>    0.578</td> <td> 0.564</td> <td>  -18.279</td> <td>   33.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Normal]</th>   <td>   17.3191</td> <td>   17.764</td> <td>    0.975</td> <td> 0.330</td> <td>  -17.618</td> <td>   52.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Poison]</th>   <td>    0.7770</td> <td>   14.575</td> <td>    0.053</td> <td> 0.958</td> <td>  -27.887</td> <td>   29.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Psychic]</th>  <td>    4.2480</td> <td>   14.174</td> <td>    0.300</td> <td> 0.765</td> <td>  -23.628</td> <td>   32.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Rock]</th>     <td>    6.8858</td> <td>   16.221</td> <td>    0.424</td> <td> 0.671</td> <td>  -25.017</td> <td>   38.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Steel]</th>    <td>  -11.9623</td> <td>   14.973</td> <td>   -0.799</td> <td> 0.425</td> <td>  -41.409</td> <td>   17.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Water]</th>    <td>    5.8097</td> <td>   14.763</td> <td>    0.394</td> <td> 0.694</td> <td>  -23.225</td> <td>   34.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                     <td>    0.2508</td> <td>    0.051</td> <td>    4.940</td> <td> 0.000</td> <td>    0.151</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                    <td>   -0.0096</td> <td>    0.060</td> <td>   -0.160</td> <td> 0.873</td> <td>   -0.127</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                      <td>   -0.1538</td> <td>    0.051</td> <td>   -2.998</td> <td> 0.003</td> <td>   -0.255</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>               <td>    0.3484</td> <td>    0.059</td> <td>    5.936</td> <td> 0.000</td> <td>    0.233</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>               <td>    0.1298</td> <td>    0.051</td> <td>    2.525</td> <td> 0.012</td> <td>    0.029</td> <td>    0.231</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>286.476</td> <th>  Durbin-Watson:     </th> <td>   1.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5187.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.807</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.725</td>  <th>  Cond. No.          </th> <td>9.21e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.21e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}             &        HP        & \\textbf{  R-squared:         } &     0.392   \\\\\n",
       "\\textbf{Model:}                     &       OLS        & \\textbf{  Adj. R-squared:    } &     0.313   \\\\\n",
       "\\textbf{Method:}                    &  Least Squares   & \\textbf{  F-statistic:       } &     4.948   \\\\\n",
       "\\textbf{Date:}                      & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  9.48e-19   \\\\\n",
       "\\textbf{Time:}                      &     17:16:28     & \\textbf{  Log-Likelihood:    } &   -1765.0   \\\\\n",
       "\\textbf{No. Observations:}          &         400      & \\textbf{  AIC:               } &     3624.   \\\\\n",
       "\\textbf{Df Residuals:}              &         353      & \\textbf{  BIC:               } &     3812.   \\\\\n",
       "\\textbf{Df Model:}                  &          46      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}           &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                  &      10.1046  &       14.957     &     0.676  &         0.500        &      -19.312    &       39.521     \\\\\n",
       "\\textbf{Legendary[T.True]}          &      -3.2717  &        4.943     &    -0.662  &         0.508        &      -12.992    &        6.449     \\\\\n",
       "\\textbf{C(Generation)[T.2]}         &       9.2938  &        4.015     &     2.315  &         0.021        &        1.398    &       17.189     \\\\\n",
       "\\textbf{C(Generation)[T.3]}         &       2.3150  &        3.915     &     0.591  &         0.555        &       -5.385    &       10.015     \\\\\n",
       "\\textbf{C(Generation)[T.4]}         &       4.8353  &        4.149     &     1.165  &         0.245        &       -3.325    &       12.995     \\\\\n",
       "\\textbf{C(Generation)[T.5]}         &      11.4838  &        3.960     &     2.900  &         0.004        &        3.696    &       19.272     \\\\\n",
       "\\textbf{C(Generation)[T.6]}         &       4.9206  &        4.746     &     1.037  &         0.300        &       -4.413    &       14.254     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dark]}     &      -1.4155  &        6.936     &    -0.204  &         0.838        &      -15.057    &       12.226     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dragon]}   &       0.8509  &        6.900     &     0.123  &         0.902        &      -12.720    &       14.422     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Electric]} &      -6.3641  &        6.537     &    -0.974  &         0.331        &      -19.220    &        6.491     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fairy]}    &      -1.9486  &       10.124     &    -0.192  &         0.847        &      -21.859    &       17.962     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fighting]} &       7.0308  &        7.432     &     0.946  &         0.345        &       -7.586    &       21.648     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fire]}     &       3.0779  &        6.677     &     0.461  &         0.645        &      -10.055    &       16.210     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Flying]}   &      -2.1231  &       22.322     &    -0.095  &         0.924        &      -46.025    &       41.779     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ghost]}    &       5.7343  &        8.488     &     0.676  &         0.500        &      -10.960    &       22.429     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Grass]}    &       3.3275  &        5.496     &     0.605  &         0.545        &       -7.481    &       14.136     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ground]}   &       9.5118  &        7.076     &     1.344  &         0.180        &       -4.404    &       23.428     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ice]}      &      -0.9313  &        7.717     &    -0.121  &         0.904        &      -16.108    &       14.246     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Normal]}   &      18.4816  &        5.312     &     3.479  &         0.001        &        8.034    &       28.929     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Poison]}   &       8.3411  &        7.735     &     1.078  &         0.282        &       -6.871    &       23.554     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Psychic]}  &       1.8061  &        6.164     &     0.293  &         0.770        &      -10.317    &       13.930     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Rock]}     &      -3.8558  &        6.503     &    -0.593  &         0.554        &      -16.645    &        8.933     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Steel]}    &      -4.0053  &        8.044     &    -0.498  &         0.619        &      -19.826    &       11.816     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Water]}    &       9.7988  &        5.166     &     1.897  &         0.059        &       -0.361    &       19.959     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dark]}     &       5.8719  &       15.185     &     0.387  &         0.699        &      -23.993    &       35.737     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dragon]}   &      13.2777  &       14.895     &     0.891  &         0.373        &      -16.016    &       42.571     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Electric]} &      14.3228  &       17.314     &     0.827  &         0.409        &      -19.728    &       48.374     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fairy]}    &       2.8426  &       14.268     &     0.199  &         0.842        &      -25.218    &       30.903     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fighting]} &       1.9741  &       14.089     &     0.140  &         0.889        &      -25.735    &       29.683     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fire]}     &       0.2001  &       15.730     &     0.013  &         0.990        &      -30.736    &       31.136     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Flying]}   &       6.7292  &       13.581     &     0.495  &         0.621        &      -19.980    &       33.438     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ghost]}    &     -10.9402  &       15.895     &    -0.688  &         0.492        &      -42.201    &       20.321     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Grass]}    &       2.5119  &       14.540     &     0.173  &         0.863        &      -26.084    &       31.108     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ground]}   &      13.6042  &       13.655     &     0.996  &         0.320        &      -13.250    &       40.459     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ice]}      &      19.7950  &       15.068     &     1.314  &         0.190        &       -9.840    &       49.430     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.None]}     &       7.6068  &       13.162     &     0.578  &         0.564        &      -18.279    &       33.493     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Normal]}   &      17.3191  &       17.764     &     0.975  &         0.330        &      -17.618    &       52.256     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Poison]}   &       0.7770  &       14.575     &     0.053  &         0.958        &      -27.887    &       29.441     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Psychic]}  &       4.2480  &       14.174     &     0.300  &         0.765        &      -23.628    &       32.124     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Rock]}     &       6.8858  &       16.221     &     0.424  &         0.671        &      -25.017    &       38.788     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Steel]}    &     -11.9623  &       14.973     &    -0.799  &         0.425        &      -41.409    &       17.485     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Water]}    &       5.8097  &       14.763     &     0.394  &         0.694        &      -23.225    &       34.845     \\\\\n",
       "\\textbf{Attack}                     &       0.2508  &        0.051     &     4.940  &         0.000        &        0.151    &        0.351     \\\\\n",
       "\\textbf{Defense}                    &      -0.0096  &        0.060     &    -0.160  &         0.873        &       -0.127    &        0.108     \\\\\n",
       "\\textbf{Speed}                      &      -0.1538  &        0.051     &    -2.998  &         0.003        &       -0.255    &       -0.053     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}               &       0.3484  &        0.059     &     5.936  &         0.000        &        0.233    &        0.464     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}               &       0.1298  &        0.051     &     2.525  &         0.012        &        0.029    &        0.231     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 286.476 & \\textbf{  Durbin-Watson:     } &    1.917  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5187.327  \\\\\n",
       "\\textbf{Skew:}          &   2.807 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  19.725 & \\textbf{  Cond. No.          } & 9.21e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 9.21e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.392\n",
       "Model:                            OLS   Adj. R-squared:                  0.313\n",
       "Method:                 Least Squares   F-statistic:                     4.948\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           9.48e-19\n",
       "Time:                        17:16:28   Log-Likelihood:                -1765.0\n",
       "No. Observations:                 400   AIC:                             3624.\n",
       "Df Residuals:                     353   BIC:                             3812.\n",
       "Df Model:                          46                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                     10.1046     14.957      0.676      0.500     -19.312      39.521\n",
       "Legendary[T.True]             -3.2717      4.943     -0.662      0.508     -12.992       6.449\n",
       "C(Generation)[T.2]             9.2938      4.015      2.315      0.021       1.398      17.189\n",
       "C(Generation)[T.3]             2.3150      3.915      0.591      0.555      -5.385      10.015\n",
       "C(Generation)[T.4]             4.8353      4.149      1.165      0.245      -3.325      12.995\n",
       "C(Generation)[T.5]            11.4838      3.960      2.900      0.004       3.696      19.272\n",
       "C(Generation)[T.6]             4.9206      4.746      1.037      0.300      -4.413      14.254\n",
       "C(Q(\"Type 1\"))[T.Dark]        -1.4155      6.936     -0.204      0.838     -15.057      12.226\n",
       "C(Q(\"Type 1\"))[T.Dragon]       0.8509      6.900      0.123      0.902     -12.720      14.422\n",
       "C(Q(\"Type 1\"))[T.Electric]    -6.3641      6.537     -0.974      0.331     -19.220       6.491\n",
       "C(Q(\"Type 1\"))[T.Fairy]       -1.9486     10.124     -0.192      0.847     -21.859      17.962\n",
       "C(Q(\"Type 1\"))[T.Fighting]     7.0308      7.432      0.946      0.345      -7.586      21.648\n",
       "C(Q(\"Type 1\"))[T.Fire]         3.0779      6.677      0.461      0.645     -10.055      16.210\n",
       "C(Q(\"Type 1\"))[T.Flying]      -2.1231     22.322     -0.095      0.924     -46.025      41.779\n",
       "C(Q(\"Type 1\"))[T.Ghost]        5.7343      8.488      0.676      0.500     -10.960      22.429\n",
       "C(Q(\"Type 1\"))[T.Grass]        3.3275      5.496      0.605      0.545      -7.481      14.136\n",
       "C(Q(\"Type 1\"))[T.Ground]       9.5118      7.076      1.344      0.180      -4.404      23.428\n",
       "C(Q(\"Type 1\"))[T.Ice]         -0.9313      7.717     -0.121      0.904     -16.108      14.246\n",
       "C(Q(\"Type 1\"))[T.Normal]      18.4816      5.312      3.479      0.001       8.034      28.929\n",
       "C(Q(\"Type 1\"))[T.Poison]       8.3411      7.735      1.078      0.282      -6.871      23.554\n",
       "C(Q(\"Type 1\"))[T.Psychic]      1.8061      6.164      0.293      0.770     -10.317      13.930\n",
       "C(Q(\"Type 1\"))[T.Rock]        -3.8558      6.503     -0.593      0.554     -16.645       8.933\n",
       "C(Q(\"Type 1\"))[T.Steel]       -4.0053      8.044     -0.498      0.619     -19.826      11.816\n",
       "C(Q(\"Type 1\"))[T.Water]        9.7988      5.166      1.897      0.059      -0.361      19.959\n",
       "C(Q(\"Type 2\"))[T.Dark]         5.8719     15.185      0.387      0.699     -23.993      35.737\n",
       "C(Q(\"Type 2\"))[T.Dragon]      13.2777     14.895      0.891      0.373     -16.016      42.571\n",
       "C(Q(\"Type 2\"))[T.Electric]    14.3228     17.314      0.827      0.409     -19.728      48.374\n",
       "C(Q(\"Type 2\"))[T.Fairy]        2.8426     14.268      0.199      0.842     -25.218      30.903\n",
       "C(Q(\"Type 2\"))[T.Fighting]     1.9741     14.089      0.140      0.889     -25.735      29.683\n",
       "C(Q(\"Type 2\"))[T.Fire]         0.2001     15.730      0.013      0.990     -30.736      31.136\n",
       "C(Q(\"Type 2\"))[T.Flying]       6.7292     13.581      0.495      0.621     -19.980      33.438\n",
       "C(Q(\"Type 2\"))[T.Ghost]      -10.9402     15.895     -0.688      0.492     -42.201      20.321\n",
       "C(Q(\"Type 2\"))[T.Grass]        2.5119     14.540      0.173      0.863     -26.084      31.108\n",
       "C(Q(\"Type 2\"))[T.Ground]      13.6042     13.655      0.996      0.320     -13.250      40.459\n",
       "C(Q(\"Type 2\"))[T.Ice]         19.7950     15.068      1.314      0.190      -9.840      49.430\n",
       "C(Q(\"Type 2\"))[T.None]         7.6068     13.162      0.578      0.564     -18.279      33.493\n",
       "C(Q(\"Type 2\"))[T.Normal]      17.3191     17.764      0.975      0.330     -17.618      52.256\n",
       "C(Q(\"Type 2\"))[T.Poison]       0.7770     14.575      0.053      0.958     -27.887      29.441\n",
       "C(Q(\"Type 2\"))[T.Psychic]      4.2480     14.174      0.300      0.765     -23.628      32.124\n",
       "C(Q(\"Type 2\"))[T.Rock]         6.8858     16.221      0.424      0.671     -25.017      38.788\n",
       "C(Q(\"Type 2\"))[T.Steel]      -11.9623     14.973     -0.799      0.425     -41.409      17.485\n",
       "C(Q(\"Type 2\"))[T.Water]        5.8097     14.763      0.394      0.694     -23.225      34.845\n",
       "Attack                         0.2508      0.051      4.940      0.000       0.151       0.351\n",
       "Defense                       -0.0096      0.060     -0.160      0.873      -0.127       0.108\n",
       "Speed                         -0.1538      0.051     -2.998      0.003      -0.255      -0.053\n",
       "Q(\"Sp. Def\")                   0.3484      0.059      5.936      0.000       0.233       0.464\n",
       "Q(\"Sp. Atk\")                   0.1298      0.051      2.525      0.012       0.029       0.231\n",
       "==============================================================================\n",
       "Omnibus:                      286.476   Durbin-Watson:                   1.917\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5187.327\n",
       "Skew:                           2.807   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.725   Cond. No.                     9.21e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.21e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model5_linear_form = 'HP ~ Attack + Defense + Speed + Legendary'\n",
    "model5_linear_form += ' + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "model5_linear_form += ' + C(Generation) + C(Q(\"Type 1\")) + C(Q(\"Type 2\"))'\n",
    "\n",
    "model5_spec = smf.ols(formula=model5_linear_form, data=pokeaman_train)\n",
    "model5_fit = model5_spec.fit()\n",
    "model5_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b587843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3920134083531893\n",
      "'Out of sample' R-squared: 0.30015614488652215\n"
     ]
    }
   ],
   "source": [
    "yhat_model5 = model5_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model5_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model5)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e00132",
   "metadata": {},
   "source": [
    "This model includes continuous predictors (`Attack`, `Defense`, `Speed`, `Sp. Def`, `Sp. Atk`) and a binary indicator (`Legendary`) to capture whether a Pokémon is \"Legendary\" (which may influence its `HP`).\n",
    "\n",
    "It also includes categorical variables (`Generation`, `Type 1`, and `Type 2`) to account for generation and Pokémon type effects. Categorical variables are specified with `C(...)` to indicate that they should be treated as categories, not continuous numbers.\n",
    "\n",
    "The formula adds main effects (no interaction terms) for each of the predictors. By avoiding interactions, the model keeps complexity lower than model4, reducing multicollinearity.\n",
    "\n",
    "The goal of model5 is to capture a more comprehensive set of characteristics influencing HP without creating a large number of interaction terms, which would increase multicollinearity.\n",
    "\n",
    "By including categorical variables and main effects only, the model aims to provide a good fit while maintaining generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "273f0edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>2.25e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:16:29</td>     <th>  Log-Likelihood:    </th> <td> -1783.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3585.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   391</td>      <th>  BIC:               </th> <td>   3621.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                          <td>   22.8587</td> <td>    3.876</td> <td>    5.897</td> <td> 0.000</td> <td>   15.238</td> <td>   30.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th> <td>   17.5594</td> <td>    3.339</td> <td>    5.258</td> <td> 0.000</td> <td>   10.994</td> <td>   24.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>  <td>    9.0301</td> <td>    3.172</td> <td>    2.847</td> <td> 0.005</td> <td>    2.794</td> <td>   15.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>         <td>    6.5293</td> <td>    2.949</td> <td>    2.214</td> <td> 0.027</td> <td>    0.732</td> <td>   12.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>         <td>    8.4406</td> <td>    2.711</td> <td>    3.114</td> <td> 0.002</td> <td>    3.112</td> <td>   13.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                             <td>    0.2454</td> <td>    0.037</td> <td>    6.639</td> <td> 0.000</td> <td>    0.173</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                              <td>   -0.1370</td> <td>    0.045</td> <td>   -3.028</td> <td> 0.003</td> <td>   -0.226</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                       <td>    0.3002</td> <td>    0.045</td> <td>    6.662</td> <td> 0.000</td> <td>    0.212</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                       <td>    0.1192</td> <td>    0.042</td> <td>    2.828</td> <td> 0.005</td> <td>    0.036</td> <td>    0.202</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>271.290</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4238.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.651</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>18.040</td>  <th>  Cond. No.          </th> <td>    618.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                     &        HP        & \\textbf{  R-squared:         } &     0.333   \\\\\n",
       "\\textbf{Model:}                             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.319   \\\\\n",
       "\\textbf{Method:}                            &  Least Squares   & \\textbf{  F-statistic:       } &     24.36   \\\\\n",
       "\\textbf{Date:}                              & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  2.25e-30   \\\\\n",
       "\\textbf{Time:}                              &     17:16:29     & \\textbf{  Log-Likelihood:    } &   -1783.6   \\\\\n",
       "\\textbf{No. Observations:}                  &         400      & \\textbf{  AIC:               } &     3585.   \\\\\n",
       "\\textbf{Df Residuals:}                      &         391      & \\textbf{  BIC:               } &     3621.   \\\\\n",
       "\\textbf{Df Model:}                          &           8      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                          &      22.8587  &        3.876     &     5.897  &         0.000        &       15.238    &       30.479     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]} &      17.5594  &        3.339     &     5.258  &         0.000        &       10.994    &       24.125     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}  &       9.0301  &        3.172     &     2.847  &         0.005        &        2.794    &       15.266     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}         &       6.5293  &        2.949     &     2.214  &         0.027        &        0.732    &       12.327     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}         &       8.4406  &        2.711     &     3.114  &         0.002        &        3.112    &       13.770     \\\\\n",
       "\\textbf{Attack}                             &       0.2454  &        0.037     &     6.639  &         0.000        &        0.173    &        0.318     \\\\\n",
       "\\textbf{Speed}                              &      -0.1370  &        0.045     &    -3.028  &         0.003        &       -0.226    &       -0.048     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                       &       0.3002  &        0.045     &     6.662  &         0.000        &        0.212    &        0.389     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                       &       0.1192  &        0.042     &     2.828  &         0.005        &        0.036    &        0.202     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 271.290 & \\textbf{  Durbin-Watson:     } &    1.999  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 4238.692  \\\\\n",
       "\\textbf{Skew:}          &   2.651 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  18.040 & \\textbf{  Cond. No.          } &     618.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.333\n",
       "Model:                            OLS   Adj. R-squared:                  0.319\n",
       "Method:                 Least Squares   F-statistic:                     24.36\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           2.25e-30\n",
       "Time:                        17:16:29   Log-Likelihood:                -1783.6\n",
       "No. Observations:                 400   AIC:                             3585.\n",
       "Df Residuals:                     391   BIC:                             3621.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================================\n",
       "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------\n",
       "Intercept                             22.8587      3.876      5.897      0.000      15.238      30.479\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]    17.5594      3.339      5.258      0.000      10.994      24.125\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]      9.0301      3.172      2.847      0.005       2.794      15.266\n",
       "I(Generation == 2)[T.True]             6.5293      2.949      2.214      0.027       0.732      12.327\n",
       "I(Generation == 5)[T.True]             8.4406      2.711      3.114      0.002       3.112      13.770\n",
       "Attack                                 0.2454      0.037      6.639      0.000       0.173       0.318\n",
       "Speed                                 -0.1370      0.045     -3.028      0.003      -0.226      -0.048\n",
       "Q(\"Sp. Def\")                           0.3002      0.045      6.662      0.000       0.212       0.389\n",
       "Q(\"Sp. Atk\")                           0.1192      0.042      2.828      0.005       0.036       0.202\n",
       "==============================================================================\n",
       "Omnibus:                      271.290   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4238.692\n",
       "Skew:                           2.651   Prob(JB):                         0.00\n",
       "Kurtosis:                      18.040   Cond. No.                         618.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model6_linear_form = 'HP ~ Attack + Speed + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "# And here we'll add the significant indicators from the previous model\n",
    "# https://chatgpt.com/share/81ab88df-4f07-49f9-a44a-de0cfd89c67c\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model6_linear_form += ' + I(Generation==2)'\n",
    "model6_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model6_spec = smf.ols(formula=model6_linear_form, data=pokeaman_train)\n",
    "model6_fit = model6_spec.fit()\n",
    "model6_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "421e76eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908\n",
      "'Out of sample' R-squared: 0.29572460427079933\n"
     ]
    }
   ],
   "source": [
    "yhat_model6 = model6_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56781ed2",
   "metadata": {},
   "source": [
    "Instead of including all continuous predictors from model5, model6 focuses on those that were significant in `model5`.\n",
    "\n",
    "For categorical variables, specific levels (categories) that were more predictive of `HP` in `model5` are selected.\n",
    "\n",
    "This focused approach minimizes the complexity of the model by avoiding irrelevant or less important categories.\n",
    "\n",
    "This model is more selective, keeping only the most influential variables identified from `model5`.\n",
    "\n",
    "By focusing on significant predictors, `model6` reduces potential noise from non-essential variables, aiming to improve model stability and enhance out-of-sample performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8b7e50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.20e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:16:30</td>     <th>  Log-Likelihood:    </th> <td> -1769.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3579.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   380</td>      <th>  BIC:               </th> <td>   3659.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                     <td></td>                       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                              <td>   95.1698</td> <td>   34.781</td> <td>    2.736</td> <td> 0.007</td> <td>   26.783</td> <td>  163.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th>     <td>   18.3653</td> <td>    3.373</td> <td>    5.445</td> <td> 0.000</td> <td>   11.733</td> <td>   24.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>      <td>    9.2913</td> <td>    3.140</td> <td>    2.959</td> <td> 0.003</td> <td>    3.117</td> <td>   15.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>             <td>    7.0711</td> <td>    2.950</td> <td>    2.397</td> <td> 0.017</td> <td>    1.271</td> <td>   12.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>             <td>    7.8557</td> <td>    2.687</td> <td>    2.923</td> <td> 0.004</td> <td>    2.572</td> <td>   13.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                 <td>   -0.6975</td> <td>    0.458</td> <td>   -1.523</td> <td> 0.129</td> <td>   -1.598</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                  <td>   -1.8147</td> <td>    0.554</td> <td>   -3.274</td> <td> 0.001</td> <td>   -2.905</td> <td>   -0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                           <td>    0.0189</td> <td>    0.007</td> <td>    2.882</td> <td> 0.004</td> <td>    0.006</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                           <td>   -0.5532</td> <td>    0.546</td> <td>   -1.013</td> <td> 0.312</td> <td>   -1.627</td> <td>    0.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                    <td>    0.0090</td> <td>    0.007</td> <td>    1.311</td> <td> 0.191</td> <td>   -0.004</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                     <td>    0.0208</td> <td>    0.008</td> <td>    2.571</td> <td> 0.011</td> <td>    0.005</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>              <td>   -0.0002</td> <td> 9.06e-05</td> <td>   -2.277</td> <td> 0.023</td> <td>   -0.000</td> <td>-2.82e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                           <td>   -0.7277</td> <td>    0.506</td> <td>   -1.439</td> <td> 0.151</td> <td>   -1.722</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                    <td>    0.0136</td> <td>    0.005</td> <td>    2.682</td> <td> 0.008</td> <td>    0.004</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                     <td>    0.0146</td> <td>    0.007</td> <td>    2.139</td> <td> 0.033</td> <td>    0.001</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>              <td>   -0.0002</td> <td>  5.4e-05</td> <td>   -3.383</td> <td> 0.001</td> <td>   -0.000</td> <td>-7.65e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0103</td> <td>    0.007</td> <td>    1.516</td> <td> 0.130</td> <td>   -0.003</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>   -0.0001</td> <td> 6.71e-05</td> <td>   -2.119</td> <td> 0.035</td> <td>   -0.000</td> <td>-1.03e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0002</td> <td> 8.82e-05</td> <td>   -2.075</td> <td> 0.039</td> <td>   -0.000</td> <td>-9.62e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>  2.03e-06</td> <td> 7.42e-07</td> <td>    2.734</td> <td> 0.007</td> <td>  5.7e-07</td> <td> 3.49e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.34e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                         &        HP        & \\textbf{  R-squared:         } &     0.378   \\\\\n",
       "\\textbf{Model:}                                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.347   \\\\\n",
       "\\textbf{Method:}                                &  Least Squares   & \\textbf{  F-statistic:       } &     12.16   \\\\\n",
       "\\textbf{Date:}                                  & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.20e-29   \\\\\n",
       "\\textbf{Time:}                                  &     17:16:30     & \\textbf{  Log-Likelihood:    } &   -1769.5   \\\\\n",
       "\\textbf{No. Observations:}                      &         400      & \\textbf{  AIC:               } &     3579.   \\\\\n",
       "\\textbf{Df Residuals:}                          &         380      & \\textbf{  BIC:               } &     3659.   \\\\\n",
       "\\textbf{Df Model:}                              &          19      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                              &      95.1698  &       34.781     &     2.736  &         0.007        &       26.783    &      163.556     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]}     &      18.3653  &        3.373     &     5.445  &         0.000        &       11.733    &       24.997     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}      &       9.2913  &        3.140     &     2.959  &         0.003        &        3.117    &       15.466     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}             &       7.0711  &        2.950     &     2.397  &         0.017        &        1.271    &       12.871     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}             &       7.8557  &        2.687     &     2.923  &         0.004        &        2.572    &       13.140     \\\\\n",
       "\\textbf{Attack}                                 &      -0.6975  &        0.458     &    -1.523  &         0.129        &       -1.598    &        0.203     \\\\\n",
       "\\textbf{Speed}                                  &      -1.8147  &        0.554     &    -3.274  &         0.001        &       -2.905    &       -0.725     \\\\\n",
       "\\textbf{Attack:Speed}                           &       0.0189  &        0.007     &     2.882  &         0.004        &        0.006    &        0.032     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                           &      -0.5532  &        0.546     &    -1.013  &         0.312        &       -1.627    &        0.521     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                    &       0.0090  &        0.007     &     1.311  &         0.191        &       -0.004    &        0.023     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                     &       0.0208  &        0.008     &     2.571  &         0.011        &        0.005    &        0.037     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}              &      -0.0002  &     9.06e-05     &    -2.277  &         0.023        &       -0.000    &    -2.82e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                           &      -0.7277  &        0.506     &    -1.439  &         0.151        &       -1.722    &        0.267     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                    &       0.0136  &        0.005     &     2.682  &         0.008        &        0.004    &        0.024     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                     &       0.0146  &        0.007     &     2.139  &         0.033        &        0.001    &        0.028     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}              &      -0.0002  &      5.4e-05     &    -3.383  &         0.001        &       -0.000    &    -7.65e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0103  &        0.007     &     1.516  &         0.130        &       -0.003    &        0.024     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &      -0.0001  &     6.71e-05     &    -2.119  &         0.035        &       -0.000    &    -1.03e-05     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0002  &     8.82e-05     &    -2.075  &         0.039        &       -0.000    &    -9.62e-06     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &     2.03e-06  &     7.42e-07     &     2.734  &         0.007        &      5.7e-07    &     3.49e-06     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.34e+09. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.378\n",
       "Model:                            OLS   Adj. R-squared:                  0.347\n",
       "Method:                 Least Squares   F-statistic:                     12.16\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           4.20e-29\n",
       "Time:                        17:16:30   Log-Likelihood:                -1769.5\n",
       "No. Observations:                 400   AIC:                             3579.\n",
       "Df Residuals:                     380   BIC:                             3659.\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================================\n",
       "                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------\n",
       "Intercept                                 95.1698     34.781      2.736      0.007      26.783     163.556\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]        18.3653      3.373      5.445      0.000      11.733      24.997\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]          9.2913      3.140      2.959      0.003       3.117      15.466\n",
       "I(Generation == 2)[T.True]                 7.0711      2.950      2.397      0.017       1.271      12.871\n",
       "I(Generation == 5)[T.True]                 7.8557      2.687      2.923      0.004       2.572      13.140\n",
       "Attack                                    -0.6975      0.458     -1.523      0.129      -1.598       0.203\n",
       "Speed                                     -1.8147      0.554     -3.274      0.001      -2.905      -0.725\n",
       "Attack:Speed                               0.0189      0.007      2.882      0.004       0.006       0.032\n",
       "Q(\"Sp. Def\")                              -0.5532      0.546     -1.013      0.312      -1.627       0.521\n",
       "Attack:Q(\"Sp. Def\")                        0.0090      0.007      1.311      0.191      -0.004       0.023\n",
       "Speed:Q(\"Sp. Def\")                         0.0208      0.008      2.571      0.011       0.005       0.037\n",
       "Attack:Speed:Q(\"Sp. Def\")                 -0.0002   9.06e-05     -2.277      0.023      -0.000   -2.82e-05\n",
       "Q(\"Sp. Atk\")                              -0.7277      0.506     -1.439      0.151      -1.722       0.267\n",
       "Attack:Q(\"Sp. Atk\")                        0.0136      0.005      2.682      0.008       0.004       0.024\n",
       "Speed:Q(\"Sp. Atk\")                         0.0146      0.007      2.139      0.033       0.001       0.028\n",
       "Attack:Speed:Q(\"Sp. Atk\")                 -0.0002    5.4e-05     -3.383      0.001      -0.000   -7.65e-05\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0103      0.007      1.516      0.130      -0.003       0.024\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          -0.0001   6.71e-05     -2.119      0.035      -0.000   -1.03e-05\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0002   8.82e-05     -2.075      0.039      -0.000   -9.62e-06\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")   2.03e-06   7.42e-07      2.734      0.007     5.7e-07    3.49e-06\n",
       "==============================================================================\n",
       "Omnibus:                      252.300   Durbin-Watson:                   1.953\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3474.611\n",
       "Skew:                           2.438   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.590   Cond. No.                     2.34e+09\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.34e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhaps improve prediction...\n",
    "model7_linear_form = 'HP ~ Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form += ' + I(Generation==2)'\n",
    "model7_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model7_spec = smf.ols(formula=model7_linear_form, data=pokeaman_train)\n",
    "model7_fit = model7_spec.fit()\n",
    "model7_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5f9bff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456\n",
      "'Out of sample' R-squared: 0.35055389205977444\n"
     ]
    }
   ],
   "source": [
    "yhat_model7 = model7_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9655b156",
   "metadata": {},
   "source": [
    "`model7` includes interactions among continuous variables (`Attack`, `Speed`, `Sp. Def`, and `Sp. Atk`). This means that every two-way, three-way, and four-way combination of these variables is added as a predictor.\n",
    "\n",
    "For example, `Attack * Speed` includes the main effects of `Attack` and `Speed` and their interaction term, `Attack:Speed`.\n",
    "\n",
    "Binary indicators for `Type 1 == \"Normal\"`, `Type 1 == \"Water\"`, `Generation == 2`, and `Generation == 5` are retained.\n",
    "\n",
    "By selectively introducing interactions only among continuous predictors, the model aims to capture more complex relationships without the explosion of terms seen in `model4`.\n",
    "\n",
    "This approach allows `model7` to potentially capture nuanced effects, such as how `Attack` and `Speed` together might influence `HP`, but without the excessive complexity from interacting categorical variables.\n",
    "\n",
    "The condition number is likely high without centering and scaling due to the interaction terms, which can introduce multicollinearity. High multicollinearity makes the model less stable and hurts out-of-sample performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "872cd431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>    15.4</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } &     15.4  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhas improve prediction...\n",
    "model7_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Speed))'\n",
    "model7_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# We DO NOT center and scale indicator variables\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form_CS += ' + I(Generation==2)'\n",
    "model7_linear_form_CS += ' + I(Generation==5)'\n",
    "\n",
    "model7_CS_spec = smf.ols(formula=model7_linear_form_CS, data=pokeaman_train)\n",
    "model7_CS_fit = model7_CS_spec.fit()\n",
    "model7_CS_fit.summary().tables[-1] \n",
    "# \"Cond. No.\" is NOW 15.4 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b96bbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 2,340,000,000 WITHOUT to centering and scaling\n",
    "model7_fit.summary().tables[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b5e92c",
   "metadata": {},
   "source": [
    "This version of model7 applies centering and scaling to each continuous variable before interactions are calculated. center() adjusts each variable to have a mean of 0, and scale() normalizes them to a standard deviation of 1.\n",
    "\n",
    "Centering and scaling help reduce the differences in scale among predictors, which can stabilize interactions by making predictor ranges more comparable.\n",
    "\n",
    "Centering and scaling reduce multicollinearity by decreasing dependencies among interaction terms. For instance, `Attack * Speed` after centering and scaling will not dominate or distort the model due to differences in scale.\n",
    "\n",
    "This version of model7 aims to retain complex interactions while avoiding the multicollinearity that interaction terms typically introduce. With lower multicollinearity, this model should generalize better, providing more stable predictions on new data.\n",
    "\n",
    "Centering: center()  adjusts each variable to have a mean of zero. This is done by subtracting the mean of each variable from its values, resulting in a new variable that is centered around zero.\n",
    "\n",
    "Scaling: scale() adjusts each variable to have a standard deviation of one. This is done by dividing each centered variable by its standard deviation, making each variable unitless and on a comparable scale.\n",
    "\n",
    "Using Centering and Scaling reduces the effect caused by each variable itself. Thus reduce the multicollinearity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19cbef2",
   "metadata": {},
   "source": [
    "To summary:\n",
    "\n",
    "Model 5: Adds predictors and categories without interactions, striking a balance between simplicity and comprehensiveness.\n",
    "\n",
    "Model 6: Selectively includes significant predictors from Model 5, enhancing focus and potentially improving generalization.\n",
    "\n",
    "Model 7: Introduces selective interactions for complex relationships, with centering and scaling to manage multicollinearity, improving prediction stability and generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e7aec6",
   "metadata": {},
   "source": [
    "## 8. Work with a ChatBot to write a for loop to create, collect, and visualize many different paired \"in sample\" and \"out of sample\" model performance metric actualizations (by not using np.random.seed(130) within each loop iteration); and explain in your own words the meaning of your results and purpose of this demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76c93d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define linear form based on model3 specification\n",
    "linear_form = 'HP ~ Attack + Defense'\n",
    "\n",
    "# Number of repetitions for analysis\n",
    "reps = 100\n",
    "# Arrays to store in-sample and out-of-sample R-squared values\n",
    "in_sample_Rsquared = np.zeros(reps)\n",
    "out_of_sample_Rsquared = np.zeros(reps)\n",
    "\n",
    "# Loop to perform multiple train-test splits and collect performance metrics\n",
    "for i in range(reps):\n",
    "    # 50-50 train-test split without a fixed random seed\n",
    "    pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=0.5)\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model_fit = smf.ols(formula=linear_form, data=pokeaman_train).fit()\n",
    "    \n",
    "    # Record in-sample R-squared\n",
    "    in_sample_Rsquared[i] = model_fit.rsquared\n",
    "    \n",
    "    # Calculate and record out-of-sample R-squared\n",
    "    out_of_sample_Rsquared[i] = np.corrcoef(\n",
    "        pokeaman_test.HP, model_fit.predict(pokeaman_test))[0,1]**2\n",
    "\n",
    "# Create a DataFrame to store the R-squared values\n",
    "df = pd.DataFrame({\n",
    "    \"In Sample Performance (R-squared)\": in_sample_Rsquared,\n",
    "    \"Out of Sample Performance (R-squared)\": out_of_sample_Rsquared\n",
    "})\n",
    "\n",
    "# Visualization\n",
    "fig = px.scatter(df, x=\"In Sample Performance (R-squared)\", \n",
    "                 y=\"Out of Sample Performance (R-squared)\",\n",
    "                 title=\"In-Sample vs Out-of-Sample Performance (R-squared)\")\n",
    "\n",
    "# Add a y=x line for reference\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode=\"lines\", name=\"y=x\", \n",
    "                         line=dict(dash=\"dash\")))\n",
    "\n",
    "fig.show(renderer=\"png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c0990",
   "metadata": {},
   "source": [
    "By analyzing performance across multiple random splits, we can see if the model consistently generalizes well or if its performance varies widely, indicating sensitivity to the specific train-test split.\n",
    "\n",
    "If out-of-sample $R^2$ values are consistently lower than in-sample $R^2$, the model may be overfitting.\n",
    "\n",
    "What we’re observing here is neither overfitting nor underfitting but rather a phenomenon called sampling variability or sampling noise. Which is due to random sampling variability\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9bfcd",
   "metadata": {},
   "source": [
    "## 9. Work with a ChatBot to understand the meaning of the illustration below; and, explain this in your own words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3df34222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.35055389205977444 (original)\n",
      "'In sample' R-squared:     0.5726118179916575 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.11151363354803218 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model7_gen1_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model7_gen1_predict_future_fit = model7_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model7_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db618bcf",
   "metadata": {},
   "source": [
    "Train `Model 7` on Generation 1 Pokémon only and see how well it predicts for Pokémon in other generations.\n",
    "\n",
    "By comparing the in-sample and out-of-sample performance of the Generation 1-only model to the original model, we can see if training only on Generation 1 limits the model’s ability to generalize to other generations.\n",
    "\n",
    "The Gen1-only model appears to overfit Generation 1 data, leading to a high in-sample $R^2$ but poor generalizability to other generations since 'In sample' R-squared of gen1_predict_future is greater than 'Out of sample' R-squared.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b593c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.00224240598972694 (original)\n",
      "'In sample' R-squared:     0.3904756578094535 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.23394915464343125 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model7_gen1to5_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model7_gen1to5_predict_future_fit = model7_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model7_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e43fd5",
   "metadata": {},
   "source": [
    "Training Model 7 on Generations 1 through 5 and testing it on Generation 6 to evaluate how well a model trained on historical data (earlier generations) can predict the latest data. \n",
    "\n",
    "Comparing with model7_fit (trained on all generations) lets us see if excluding Generation 6 from the training data impacts generalizability to this newest generation.\n",
    "\n",
    "The Gen1–5 model’s in-sample $R^2$ (0.390) is close to the original, suggesting it captures similar patterns in the training data.\n",
    "\n",
    "The Gen1–5 model has a higher out-of-sample  $R^2$ of 0.234 when predicting Generation 6 compared to the original model’s performance (0.002) on this test set.\n",
    "\n",
    "Conclusion: Training on a broader range of generations (1–5) provides better predictive accuracy for Generation 6, though it’s still not perfect. This suggests that exposure to multiple generations helps generalize better to newer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fb81b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.005958087895268586 (original)\n",
      "'In sample' R-squared:     0.4433880517727282 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.1932858534276128 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model6_gen1_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model6_gen1_predict_future_fit = model6_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model6_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712bdb4d",
   "metadata": {},
   "source": [
    "This code trains Model 6 on Generation 1 only and tests it on later generations, similar to how we tested Model 7 with Generation 1-only data.\n",
    "\n",
    "The in-sample and out-of-sample $R^2$ values provide insights into Model 6’s generalizability when trained on just Generation 1 data.\n",
    "\n",
    "The Gen1-only model has a higher in-sample $R^2$ (0.443), suggesting overfitting to Generation 1.\n",
    "\n",
    "Despite this overfitting, the Gen1-only model achieves a relatively higher out-of-sample $R^2$ (0.193) than the original model (0.006), indicating some ability to generalize, though not strongly.\n",
    "\n",
    "Conclusion: Model 6 trained only on Generation 1 does not generalize well to later generations, as evidenced by the drop in out-of-sample $R^2$. However, it performs slightly better than the original model on later generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28531ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.005958087895268586 (original)\n",
      "'In sample' R-squared:     0.33517279824114776 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.26262690178799936 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model6_gen1to5_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model6_gen1to5_predict_future_fit = model6_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model6_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52f409",
   "metadata": {},
   "source": [
    "Here, Model 6 is trained on Generations 1 to 5 and tested on Generation 6.\n",
    "\n",
    "This setup examines how well Model 6 generalizes to new Pokémon types and stats introduced in the latest generation when it has been trained only on older data.\n",
    "\n",
    "The Gen1–5 model’s in-sample $R^2$ (0.335) is similar to the original model’s in-sample performance (0.333), indicating it captures similar patterns in the training data.\n",
    "\n",
    "The Gen1–5 model’s out-of-sample $R^2$ (0.263) is close to the original model’s out-of-sample $R^2$ (0.296), indicating that training on Generations 1–5 allows it to generalize relatively well to Generation 6.\n",
    "\n",
    "Conclusion: Training Model 6 on Generations 1–5 provides a balance between fitting the training data and generalizing to Generation 6, similar to the original model trained on all generations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
