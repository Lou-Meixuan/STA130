{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aff84c4",
   "metadata": {},
   "source": [
    "# \"Prelecture\" HW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62425feb",
   "metadata": {},
   "source": [
    "*link to chat log histories:* https://chatgpt.com/share/c848195d-5099-4f17-be73-50b1b2920bcd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8189e",
   "metadata": {},
   "source": [
    "## 0.1\n",
    "TUT notebook has links to example ChatBot sessions and I choose one of the dataset. The URL is \"https://data.cityofnewyork.us/resource/vfnx-vebw.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f085188",
   "metadata": {},
   "source": [
    "## 0.2\n",
    "I start a new ChatBot session asking chatGPT to provide the code to print out the number of rows and columns of the dataset and the chat history is as followed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc0f80",
   "metadata": {},
   "source": [
    "### Chat History:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a180ebd3",
   "metadata": {},
   "source": [
    "#### YOU:\n",
    "Hi chat, I've downloaded a dataset from https://data.cityofnewyork.us/resource/vfnx-vebw.csv, and I'd like to know what is the number of rows of the dataset and what is the number of columns of the dataset  and the size of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d91f359",
   "metadata": {},
   "source": [
    "#### ChatGPT:\n",
    "It seems like I can’t do more advanced data analysis right now. Please try again later. You can use the following steps to check the number of rows, columns, and the size of your dataset using pandas on your local environment:\n",
    "1. Import pandas and load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfad323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('path_to_your_downloaded_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39226db9",
   "metadata": {},
   "source": [
    "2. To check the number of rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_columns = dataset.shape\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9d25a3",
   "metadata": {},
   "source": [
    "3. To check the size of the dataset in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = dataset.memory_usage(deep=True).sum()\n",
    "print(f\"Dataset size: {dataset_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f6c617",
   "metadata": {},
   "source": [
    "This will give you the information you're looking for!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5771877",
   "metadata": {},
   "source": [
    "#### YOU:\n",
    "Can you explain meaning of \"observations\" and \"variables\" in the context of your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754e866",
   "metadata": {},
   "source": [
    "#### ChatGPT:\n",
    "In the context of a dataset, \"observations\" and \"variables\" refer to fundamental concepts used to describe its structure:\n",
    "\n",
    "**Observations:**\n",
    "- Definition: An observation typically refers to a single data entry or row in a dataset. It is a collection of values or data points that represent a single instance of the entity being studied or measured.\n",
    "- Example: In a dataset of New York City building permits, each observation might be a record of a single permit. It could contain details like the permit number, issue date, applicant, and location.\n",
    "\n",
    "**Variables:**\n",
    "- Definition: A variable is a column in the dataset, representing a particular attribute or characteristic measured across all observations. Each variable captures the same type of data for every observation in the dataset.\n",
    "- Example: In the building permits dataset, variables could include \"Permit Number,\" \"Applicant Name,\" \"Issue Date,\" and \"Building Type.\"\n",
    "\n",
    "**Relationship:**\n",
    "- A variable defines the type of data that is being collected (e.g., permit number, date, cost), while an observation is an instance of that data (e.g., a single permit with specific values for each variable).\n",
    "- In terms of data structure, observations = rows and variables = columns.\n",
    "\n",
    "For instance, if your dataset has 1,000 rows and 10 columns, it means you have 1,000 observations and 10 variables.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b02641a",
   "metadata": {},
   "source": [
    "### My own general definitions\n",
    "#### observations:\n",
    "Envisioning a dataset as a spreadsheet, the observations are the rows. Each observation is characterized by a set of variables that describe the properties of that particular entity or event. An observation can also be a collection of all information about a particular object in a data set.\n",
    "#### variable:\n",
    "A variable is a column in a data set. It represents a common feature or a properties that the data set contains. Also datas under each variable should be of the same type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd27945e",
   "metadata": {},
   "source": [
    "### My thoughts of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e7718b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1000\n",
      "Number of columns: 31\n",
      "(1000, 31)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('https://data.cityofnewyork.us/resource/vfnx-vebw.csv')\n",
    "num_rows, num_columns = dataset.shape\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")\n",
    "print (dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84bd2b4",
   "metadata": {},
   "source": [
    "## 0.3\n",
    "### Chat History:\n",
    "#### YOU:\n",
    "How can I provide simple summaries of the columns in the dataset? Can you use code to provide these summaries for this dataset? Can you create working examples of using `df.describe()` and `df['column'].value_counts()` for this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d06560",
   "metadata": {},
   "source": [
    "#### ChatGPT:\n",
    "Certainly! Here are two examples to demonstrate how to use `df.describe()` and `df['column'].value_counts()` with your dataset.\n",
    "\n",
    "**Example 1: Using `df.describe()`**\n",
    "This provides a summary of the statistics for numerical columns, and can also provide some summary info for categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc19487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('path_to_your_downloaded_file.csv')\n",
    "\n",
    "# Get a summary of the numerical and categorical columns\n",
    "summary = dataset.describe(include='all')\n",
    "\n",
    "# Display the summary\n",
    "print(\"Summary of Columns:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56019ca8",
   "metadata": {},
   "source": [
    "- `df.describe(include='all')` gives you information such as count, unique values, mean, standard deviation (for numerical columns), and other details like top occurring values for categorical columns.\n",
    "**Example 2: Using `df['column'].value_counts()`**\n",
    "This counts the unique values in a specific categorical column. You need to specify which column you want to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a699ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('path_to_your_downloaded_file.csv')\n",
    "\n",
    "# Example of using value_counts() on a specific column\n",
    "# Replace 'your_column_name' with the actual column name you want to explore\n",
    "value_counts = dataset['your_column_name'].value_counts()\n",
    "\n",
    "# Display the unique value counts for the column\n",
    "print(f\"Value counts for 'your_column_name':\")\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86581ced",
   "metadata": {},
   "source": [
    "- `df['your_column_name'].value_counts()` will give you a count of each unique value in the specified column.\n",
    "- Replace `'your_column_name'` with the actual column name you are interested in analyzing, such as \"Building Type\" or \"Permit Number\" depending on your dataset.\n",
    "These are working examples for summarizing data and analyzing column values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e7e1f9",
   "metadata": {},
   "source": [
    "### My thoughts of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94abb326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Columns:\n",
      "                 x            y          date  hectare_squirrel_number\n",
      "count  1000.000000  1000.000000  1.000000e+03              1000.000000\n",
      "mean    -73.967020    40.781087  1.011853e+07                 4.170000\n",
      "std       0.007698     0.010139  4.267014e+04                 3.151989\n",
      "min     -73.980961    40.765008  1.006202e+07                 1.000000\n",
      "25%     -73.972957    40.772389  1.007202e+07                 2.000000\n",
      "50%     -73.968374    40.778225  1.012202e+07                 3.000000\n",
      "75%     -73.959765    40.791285  1.014202e+07                 6.000000\n",
      "max     -73.949722    40.800046  1.020202e+07                23.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('https://data.cityofnewyork.us/resource/vfnx-vebw.csv')\n",
    "\n",
    "# Get a summary of the numerical and categorical columns\n",
    "summary = dataset.describe()\n",
    "\n",
    "# Display the summary\n",
    "print(\"Summary of Columns:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad999175",
   "metadata": {},
   "source": [
    "## 0.4\n",
    "If the dataset you're using has (a) non-numeric variables and (b) missing values in numeric variables, than the numbers of rows and columns will be shown differently by using `df.shape` and `df.describe()`. The output of `df.shape` will not be influenced by those two situations, but the output of `df.describe()` will be influenced. When `df.describe()` is counting the rows, it will not count the missing values. The \"count\" represents the number of non-missing values in each column. Also `df.describe()` will only include \"numeric\" columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf4a93",
   "metadata": {},
   "source": [
    "## 0.5\n",
    "### YOU:\n",
    "Can you help me understand the difference between the following ? \n",
    "1.an \"attribute\", such as df.shape which does not end with ()\n",
    "2.and a \"method\", such as df.describe() which does end with ()\n",
    "\n",
    "### ChatGPT:\n",
    "Certainly! Let's break down the difference between an \"attribute\" and a \"method\" in the context of pandas DataFrames (and Python objects in general).\n",
    "\n",
    "1. Attribute (like `df.shape`):\n",
    "An attribute is a property or characteristic of an object. It does not require parentheses when accessed, because it is not something you \"call\" (execute); it is simply a value or description associated with the object.\n",
    "\n",
    "- Attributes store information about the object.\n",
    "- Accessing an attribute is like asking for information about the object, not doing any operation or computation.\n",
    "\n",
    "Example: `df.shape`\n",
    "- `df.shape` is an attribute of a DataFrame that tells you its dimensions.\n",
    "- When you type `df.shape`, it returns a tuple with the number of rows and columns: `(number_of_rows, number_of_columns)`.\n",
    "- No parentheses are used because it simply retrieves this information, and no further operation is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465603c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Access the shape attribute\n",
    "print(df.shape)  # Output: (3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf45f4ab",
   "metadata": {},
   "source": [
    "2. Method (like `df.describe()`):\n",
    "A method is a function that is associated with an object. You need to use parentheses because calling a method often involves executing code or performing an action.\n",
    "\n",
    "- Methods can perform actions like computations, transformations, or operations on the data within the object.\n",
    "- A method might return a value or modify the object itself.\n",
    "\n",
    "Example: `df.describe()`\n",
    "- `df.describe()` is a method that generates summary statistics of the DataFrame's columns.\n",
    "- It requires parentheses because it needs to be called (executed), and it performs an operation to calculate the summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the describe() method\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eab120",
   "metadata": {},
   "source": [
    "This will output summary statistics such as the mean, standard deviation, min, max, etc.\n",
    "\n",
    "Summary of Differences:\n",
    "- Attribute (`df.shape`): Provides a characteristic of the DataFrame (e.g., its dimensions). It does not require parentheses because it’s not performing any computation.\n",
    "- Method (`df.describe()`): Performs an action or operation (e.g., computing summary statistics). It requires parentheses because it needs to be executed.\n",
    "\n",
    "In essence:\n",
    "\n",
    "- Attributes are data that belong to the object.\n",
    "- Methods are functions that perform actions on the object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73560215",
   "metadata": {},
   "source": [
    "## My thoughts\n",
    "Attributes store the data of an object. Methods define behavior (functions) that operate on an object or its data. \n",
    "Because attribute is not the function, it is the property or characteristic of an object so we don't need the brackets when we use it. Attribute doesn't need further operation. A method is a function that is associated with an object. When we use the method, we need brackets because we need further operation. In a word, attribute is property so it doesn't need brackets to do the further operations, method is function it need brackets to do the further operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66686f39",
   "metadata": {},
   "source": [
    "# \"Postlecture\" HW "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ce33b2",
   "metadata": {},
   "source": [
    "*links to chat log histories:* \n",
    "- https://chatgpt.com/share/8d625f1f-0ffb-4457-853e-7762707df11f\n",
    "- https://chatgpt.com/share/40581761-25a2-4c86-965d-adf384ce3fce\n",
    "- https://chatgpt.com/share/ee4262f5-4780-4e30-b57a-6d0adda0d75b\n",
    "- https://chatgpt.com/share/676e0186-4032-45d2-ab1b-0945982354ea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5081819",
   "metadata": {},
   "source": [
    "## 0.6\n",
    "**'count':** number of non-missing values in each column\n",
    "\n",
    "**'mean':** the average of all non-missing values in each column\n",
    "\n",
    "**'std':** the standard deviation, which measures how spread out the values are from the mean\n",
    "\n",
    "**'min':** the smallest value in each column\n",
    "\n",
    "**'25%':** the first quartile (Q1). It represents the value below which 25% of the data set\n",
    "\n",
    "**'50%':** the median, which is the middle value and divides the data into two equal halves\n",
    "\n",
    "**'75%':** the third quartile (Q3). It represents the value below which 75% of the data set\n",
    "\n",
    "**'max':** the largest value in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc119464",
   "metadata": {},
   "source": [
    "## 0.7\n",
    "### 0.7.1\n",
    "*Provide an example of a \"use case\" in which using `df.dropna()` might be peferred over using `del df['col']`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba9ddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B   C\n",
      "0  1.0  4.0   5\n",
      "1  2.0  NaN   9\n",
      "2  NaN  6.0   2\n",
      "3  4.0  8.0  11\n",
      "     A    B   C\n",
      "0  1.0  4.0   5\n",
      "3  4.0  8.0  11\n",
      "    C\n",
      "0   5\n",
      "1   9\n",
      "2   2\n",
      "3  11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = {'A': [1, 2, np.nan, 4], 'B': [4, np.nan, 6, 8], 'C': [5, 9, 2, 11]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print(df.dropna())\n",
    "columns_list = df.columns.tolist()\n",
    "for the_col in columns_list:\n",
    "    if df[the_col].isna().sum() > 0:\n",
    "        del df[the_col]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc4c6a",
   "metadata": {},
   "source": [
    "The first output dataset is the original dataset, the second dataset is the output dataset of `df.dropna()` and the last one is the output dataset of `del df['col']`. We can see that in this example, there are many important information being deleted by `del df['col']`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016432ce",
   "metadata": {},
   "source": [
    "### 0.7.2\n",
    "*Provide an example of \"the opposite use case\" in which using `del df['col']` might be preferred over using `df.dropna()`*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e19b074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_ID   Age  Rating   Comments  Satisfaction_Score\n",
      "0            1   NaN     NaN       Good                   9\n",
      "1            2  30.0     NaN    Average                   7\n",
      "2            3   NaN     3.0       Poor                   6\n",
      "3            4  40.0     NaN  Excellent                   8\n",
      "4            5   NaN     NaN  Excellent                   5\n",
      "Empty DataFrame\n",
      "Columns: [Customer_ID, Age, Rating, Comments, Satisfaction_Score]\n",
      "Index: []\n",
      "   Customer_ID   Comments  Satisfaction_Score\n",
      "0            1       Good                   9\n",
      "1            2    Average                   7\n",
      "2            3       Poor                   6\n",
      "3            4  Excellent                   8\n",
      "4            5  Excellent                   5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = {'Customer_ID': [1, 2, 3, 4, 5], \n",
    "        'Age': [np.nan, 30, np.nan, 40, np.nan], \n",
    "        'Rating': [np.nan, np.nan, 3, np.nan, np.nan], \n",
    "        'Comments': ['Good', 'Average', 'Poor', 'Excellent', 'Excellent'],\n",
    "        'Satisfaction_Score': [9, 7, 6, 8, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print(df.dropna())\n",
    "columns_list = df.columns.tolist()\n",
    "for the_col in columns_list:\n",
    "    if df[the_col].isna().sum() > 0:\n",
    "        del df[the_col]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f137ad83",
   "metadata": {},
   "source": [
    "The first output dataset is the original dataset, the second dataset is the output dataset of `df.dropna()` and the last one is the output dataset of `del df['col']`. We can see that in this example, there is nothing left after using `df.dropna()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b526d",
   "metadata": {},
   "source": [
    "### 0.7.3\n",
    "*Q:Discuss why applying `del df['col']` before `df.dropna()` when both are used together could be important*\n",
    "\n",
    "A: \n",
    "Let dataset that be 10 rows x 10 cols. Assume there is 8 missing values in col 5 from row 3 to row 10, a missing value in row 1 of col 1, a missing value in row 2 of col2. Now we must apply `del df['col']` before `df.dropna()`. Because if we use `df.dropna()` first then the dataset will become a 2 rows x 10 cols dataset. And there will be nothing left. So it is very important to use `del df['col']` first if there is many missing values in the same column. \n",
    "\n",
    "### 0.7.4\n",
    "*Remove all missing data from one of the datasets you're considering using some combination of `del df['col']` and/or `df.dropna()` and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528b9089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "  Salesperson Region    Sales  Target  Commission (%)  Customer_Rating    Year\n",
      "0        John  North  20000.0   22000             5.0              NaN  2021.0\n",
      "1        Jane  South  25000.0   27000             NaN              3.7  2021.0\n",
      "2       Alice    NaN      NaN   25000             7.0              NaN  2021.0\n",
      "3        Mike    NaN  15000.0   18000             5.0              4.0  2021.0\n",
      "4        Sara    NaN  30000.0   29000             NaN              NaN  2022.0\n",
      "5         Tom    NaN  23000.0   24000             6.0              4.2  2022.0\n",
      "6         NaN    NaN  17000.0   20000             5.0              NaN     NaN\n",
      "7        Paul  North      NaN   21000             7.0              4.1  2022.0\n",
      "\n",
      "After cleaning\n",
      "  Salesperson    Sales  Target  Commission (%)    Year\n",
      "0        John  20000.0   22000             5.0  2021.0\n",
      "3        Mike  15000.0   18000             5.0  2021.0\n",
      "5         Tom  23000.0   24000             6.0  2022.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Complex DataFrame with various missing values\n",
    "data = {\n",
    "    'Salesperson': ['John', 'Jane', 'Alice', 'Mike', 'Sara', 'Tom', np.nan, 'Paul'],\n",
    "    'Region': ['North', 'South', np.nan, np.nan, np.nan, np.nan, np.nan, 'North'],\n",
    "    'Sales': [20000, 25000, np.nan, 15000, 30000, 23000, 17000, np.nan],\n",
    "    'Target': [22000, 27000, 25000, 18000, 29000, 24000, 20000, 21000],\n",
    "    'Commission (%)': [5, np.nan, 7, 5, np.nan, 6, 5, 7],\n",
    "    'Customer_Rating': [np.nan, 3.7, np.nan, 4.0, np.nan, 4.2, np.nan, 4.1],\n",
    "    'Year': [2021, 2021, 2021, 2021, 2022, 2022, np.nan, 2022]\n",
    "}\n",
    "\n",
    "df_complex = pd.DataFrame(data)\n",
    "print(\"Before cleaning:\")\n",
    "print(df_complex)\n",
    "\n",
    "columns_list = df_complex.columns.tolist()\n",
    "for the_col in columns_list:\n",
    "    if df_complex[the_col].isna().sum() / len(df_complex) > 0.4:\n",
    "        del df_complex[the_col]\n",
    "\n",
    "print(\"\\nAfter cleaning\")\n",
    "print(df_complex.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ba863",
   "metadata": {},
   "source": [
    "By asking ChatGPT I learned that if there are up to 40% missing data it could bias any analysis. So we first check if there is a column that has more than 40% missing values, and use the `del df['col']` to delete that column. After that I use the `df.dropna()` to clean rows that have missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09121b69",
   "metadata": {},
   "source": [
    "## 0.8\n",
    "### 0.8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842153a",
   "metadata": {},
   "source": [
    "#### example from ChatGPT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dcd4474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>261.0</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>14.110146</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>453.0</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>14.678201</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "sex                                                              \n",
       "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
       "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "df_titanic.groupby(\"sex\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77cd88e",
   "metadata": {},
   "source": [
    "#### different example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7e5e330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alive</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>424.0</td>\n",
       "      <td>30.626179</td>\n",
       "      <td>14.172110</td>\n",
       "      <td>1.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>290.0</td>\n",
       "      <td>28.343690</td>\n",
       "      <td>14.950952</td>\n",
       "      <td>0.42</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count       mean        std   min   25%   50%   75%   max\n",
       "alive                                                           \n",
       "no     424.0  30.626179  14.172110  1.00  21.0  28.0  39.0  74.0\n",
       "yes    290.0  28.343690  14.950952  0.42  19.0  28.0  36.0  80.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "df_titanic.groupby(\"alive\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9469f9",
   "metadata": {},
   "source": [
    "In this code `df_titanic.groupby(\"alive\")[\"age\"].describe()`. The first part is `df_titanic.groupby(\"alive\")` which means I classify this dataset according to the variable column \"alive\". And the second part is `[\"age\"].describe()` which means I select the \"age\" column and calculates various summary statistics (like count, mean, std deviation, min, 25th percentile, 50th percentile, 75th percentile, and max) for each group in column \"alive\" based on the values of column \"age\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4322f2",
   "metadata": {},
   "source": [
    "### 0.8.2\n",
    "When I use the `df.describe()`, it gives the overall count of non-missing values for each column in the entire DataFrame. Each column is independent.\n",
    "However, when I use `df.groupby(\"col1\")[\"col2\"].describe()` it gives the count of non-missing values in col2 within each group of col1. Because of that, it need to first count how many available values are in each group of col1 and then count how many available values are in that group. \n",
    "As a result, the \"count\"s captured by `df.describe()` are something fundamentally different from `df.groupby(\"col1\")[\"col2\"].describe()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e31d8be",
   "metadata": {},
   "source": [
    "### 0.8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db303362",
   "metadata": {},
   "source": [
    "**0.8.3.(1)**\n",
    "\n",
    "`#import pandas as pd`\n",
    "\n",
    "`df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')`\n",
    "\n",
    "`df_titanic.groupby(\"alive\")[\"age\"].describe()`\n",
    "\n",
    "It output the error: `NameError: name 'pd' is not defined`\n",
    "\n",
    "When I entered the error into ChatGPT, it directly tell me how to fix it. I think it is easier to use ChatGPT than Google."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f24959",
   "metadata": {},
   "source": [
    "**0.8.3.(2)**\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "`df_titanic = pd.read_csv('titanics.csv')`\n",
    "`df_titanic.groupby(\"alive\")[\"age\"].describe()`\n",
    "\n",
    "It output the error: `FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv'`\n",
    "\n",
    "When I entered the error into ChatGPT, it directly tell me how to fix it. I think it is easier to use ChatGPT than Google.\n",
    "\n",
    "It said that error means that Python cannot find the 'titanics.csv' file in the current working directory. To resolve this, make sure that the file exists in the right location, or use the full path to the file like this: `df_titanic = pd.read_csv('/path/to/your/titanics.csv')`\n",
    "\n",
    "Also when introducing typos into a couple other parts of the url and slightly different errors will be produced. It output that : `URLError: <urlopen error [Errno 11001] getaddrinfo failed>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de9fb16",
   "metadata": {},
   "source": [
    "**0.8.3.(3)**\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "`df_titanic = pd.read_csv('titanics.csv')`   `DF_titanic.groupby(\"alive\")[\"age\"].describe()`\n",
    "\n",
    "It output the error: `NameError: name 'DF_titanic' is not defined`\n",
    "\n",
    "To fix this, ChatGPT said: change `DF_titanic` to `df_titanic` in the second line. It is more easier than Google."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5b8de8",
   "metadata": {},
   "source": [
    "**0.8.3.(4)**\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "`df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'`\n",
    "`df_titanic.groupby(\"sex\")[\"age\"].describe()`\n",
    "\n",
    "It output the error: `SyntaxError: unexpected EOF while parsing`\n",
    "\n",
    "To fix that, just add a bracket at the end of the second code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f262186",
   "metadata": {},
   "source": [
    "**0.8.3.(5)**\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "`df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')`\n",
    "`df_titanic.group_by(\"sex\")[\"age\"].describe()`\n",
    "\n",
    "It output the error: `AttributeError: 'DataFrame' object has no attribute 'group_by'`\n",
    "\n",
    "This happens because pandas has the `groupby()` method, not `group_by()`.\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "`df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')`\n",
    "`df_titanic.groupby(\"sex\")[\"age\"].describle()`\n",
    "\n",
    "It output the error: `AttributeError: 'SeriesGroupBy' object has no attribute 'describle'`\n",
    "\n",
    "This happens because `describle()` is a typo, and the correct method name is `describe()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b7a063",
   "metadata": {},
   "source": [
    "**0.8.3.(6)**\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "`df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')`\n",
    "`df_titanic.groupby(\"Sex\")[\"age\"].describe()`\n",
    "\n",
    "It output the error: `KeyError: 'Sex'`\n",
    "\n",
    "This occurs because pandas is case-sensitive, and `\"Sex\"` does not match the actual column name `\"sex\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e9567",
   "metadata": {},
   "source": [
    "**0.8.3.(7)**\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "`df_titanic = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')`\n",
    "`df_titanic.groupby(sex)[\"age\"].describe()`\n",
    "\n",
    "It output the error: `NameError: name 'sex' is not defined`\n",
    "\n",
    "This is because sex is interpreted as a variable rather than a string representing the column name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ba1d2",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "In my point of view, by entering the wrong code, the ChatGpt can immediately find the error types and fix them. It is showing the error and the way to fix it by showing the real example. But using the google search can show me the detail of the error, so I think I can handle it in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd8e58",
   "metadata": {},
   "source": [
    "## 0.9\n",
    "Mostly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
